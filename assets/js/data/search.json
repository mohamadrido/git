[ { "title": "GitHub 的 Git LFS 奇遇", "url": "/posts/strange-things-encountered-in-git-lfs-on-github/", "categories": "Tech, Git", "tags": "github, git-lfs", "date": "2021-10-25 21:32:00 +0800", "snippet": "本月 21 号晚上，我的邮箱收到一封了由 GitHub 发送，标题为「At 80% of Git LFS data quota for cotes2020」的邮件，内容是说我账号的 Git LFS 用量使用了 96% 的额度。所以马上登陆 GitHub 一探究竟，原来是一个开源仓库消耗了这些空间：看到这幅景象，开始思考问题，首先我平常在公开项目的 commit 从来没有使用 Git LFS，其次上述开源项目的体积仅有 2.64 MB, 就算全部存储在 LFS，也不应该有 0.96 GB 这么夸张的数字。所以有两个疑问： 为何会使用了 Git LFS？ 为何 LFS 用量达到 0.96 GB？翻阅 GitHub Docs 的这篇文章，里面说删除云端的 LFS 文件需要联系 GitHub Support。于是给客服发了邮件，并很快得到了回复，说有 4 个文件通过我的账号上传到 LFS 的空间，体积大概 28 KB，而且还说了一个更加惊人的事情：所有 fork 的下游仓库在 pull 以及存储都会消耗根仓库的 LFS 的空间和带宽额度1，所以这 0.96 GB 的空间是近 2k 的 fork 产生并累计到我的账号上的，这个答复解决了 疑问 2。移除 Git LFS 文件虽然 GitHub Support 帮忙在后台清零云端的存储，但这仅仅是治标，从根本解决问题是找出占用 LFS 的文件，并把它们从 LFS 迁移到常规的 Git Object。首先是定位 LFS 文件：$ cd REPO$ git lfs ls-files -a -le3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 * .nojekyll接着，根据 GitHub Support 的建议，把占用 LFS 的文件从历史中剔除，方法有很多种: git-lfs-migrate git-filter-repo BFG Repo-Cleaner git-lfs-migrate 对我的情况不适用，因为我并没有真正使用 Git LFS，下文会细述。我选用了 BFG，在每次剔除一个文件之后，再次用 git lfs ls-files -a -l 检查仓库，以免出现漏网之鱼。前后共找出了两个目标文件：e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 * .nojekylle3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 * ._scripts/py/utils/__init__.py其实过程中还出现很多在未合并 PR 里面提交的文件，因为它们都不曾出现在根项目的提交历史中，所以可以忽略不做处理。恢复 Git Object接着，是在仓库恢复上述被剔除的必要文件：touch &amp;lt;FILE_NAME&amp;gt;，这样就产生了一个空白的文件。但奇怪的是，用 git lfs ls-files 检查，居然又被 LFS 跟踪了！为了排除是本地 git-lfs 的影响的嫌疑，我使用 GitHub 网页的 Add file 在远端创建一个空文件，然后 pull 到本地，却可以通过 git lfs ls-files 的检测。这两种方式创建空文件的差异成了新的疑问，可惜一时间找不到答案。隔了一段时间，无意间使用 ls -l 时发现了一个有趣的现象：touch 创建的文件体积是 0 byte，而 GitHub 创建的空文件是 1 byte。所以是 git-lfs 会自动跟踪 0 字节文件。再上网搜索相关的问题，在 git-lfs/issue/4660 找到了这个问题的解释。看来 GitHub 远端使用 Git LFS 的原因（疑问 1）弄清了，要避免「空文件」被存入 LFS，就要让「空文件」的体积大于 0，用 dd 或 echo 都可以创建 1 byte 最小体积的文件：$ dd if=/dev/zero of=emptyfile bs=1 count=1$ echo &quot;&quot; &amp;gt; emptyfile相比 dd，使用 echo 的效果会更佳，因为输出的内容是一个换行符，生成的文件可以被文本编辑器打开，这也是 GitHub 网页的 Add file 新建文件的效果。事件总结源码的空白文件体积必须大于 0 byte，不然在推送到 GitHub 之后，会被存储在 Git LFS，即便本地没有安装 git-lfs 也会是这种结果，因为 GitHub 云端是有 git-lfs 的。其次，GitHub 没有 Git LFS 文件列表的管理页面，找 GitHub Support 也没权限查看用户文件，真的很不方便（隔壁 Bitbucket 就有这个功能），这是不希望用户迁出 LFS 空间，出售 5 刀每月的数据包服务吗？最后，剔除历史文件将会重写所有 commit 历史，造成的影响是所有的 fork 都会炸锅，没法合并。引用 About billing for Git Large File Storage &amp;#8617; " }, { "title": "开箱 GitLab Flow 的 Release 分支", "url": "/posts/change-the-git-branch-model-of-the-project/", "categories": "Tech, Git", "tags": "gitlab flow, git branching model", "date": "2021-02-01 17:47:00 +0800", "snippet": "Chirpy 项目从 v3.0.0 版开始，转型成了一个 gem-based 项目：支持在 RubyGems.org 上对外发布 gem 包，方便用户端升级。项目原本使用的是 GitLab Flow 的持续发布方案：采用 master 和 production 双子星分支。这对 gem 版本跟踪开始力不从心，所以计划将其转换成 release 分支。Release 分支GitLab Flow 的 Release 分支核心思想是： 主分支开发成熟后，商定一个语义化版本号，格式为：&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;.&amp;lt;patch&amp;gt;。如果是新的 major 或 minor 版本，就从主分支派生一个新的 release 分支，命名格式为 &amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;-stable。不过 release 分支名命没有清规戒律，如果习惯 Git Flow 风格，也可以使用 release/ 前缀，例如，release/&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;。这样可以在 Git GUI 中把所有的 release 分支归并到 release/ 目录下，方便查找管理。 只有在版本发布后，出现严重缺陷需要紧急修复时，遵循「上源优先」法则，在主分支进行修复，然后 cherry-pick 到 release 分支，然后在 release 分支上新建 tag，并增加 patch 版本号。 但是 GitLab 文档没有对 bump version (修改项目配置文件的版本号) 这个步骤的使用位置以及时机点出指引。所以在实际应用时，还需要根据自身项目情况进行细化思考。包含 Bump version 的发布流程经过一番思考与实验，个人觉得可以按照以下方式使用 release 分支： 在发布新的 major/minor 版本，从主分支最后一个 commit 上实施 bump version，然后再派生一个新的 release 分支，并在其上面创建 tag。 在发布新的 patch 版本时，从主分支分离一个新的 patch 分支，在它上面完成 hotfix，以及 bump version。完成后，把 patch 分支用 --no-ff 方式 merge 到主分支。接着，把主分支的 merge 记录 cherry-pick 到 release 分支，然后在 release 分支上创建 tag。 在实际场景中，分支模型会类似下图：主分支和 release 分支拥有一个相同的 bump version 记录，同时也是 minor 版本的第一个 tag。release 分支从第一个 hot-fix 起，与主分支各自拥有不同的提交轨迹，往后增加 patch 版本号（即 patch 大于 0）的 tag，只会存在于 release 分支。借力 Git flow上面说了对 release 分支的适配，但是开发过程的 feature 分支也值得花点笔墨提及一下。Git Flow 成名已久，也是 GitHub Flow 与 GitLab Flow 的老前辈。现在主流的 Git GUI 基本都集成了 Git Flow，因此可以在 Git GUI 上享受创建 feature 分支的便利：从 master 派生一个影子分支 develop，在它的基础上可以用 GUI 快速生成开发分枝 feature/&amp;lt;feat-name&amp;gt;，然后合并回 develop，同时自动删除 feature 分支。这些操作都是 Git Flow 的逻辑，在 GitLab Flow 模型上也可以通过 Git GUI 来享用。develop 分支某种意义上算是项目作者的私人长期 feature 分支，对于使用 Codacy 之类代码质量审核的项目，还能把 develop 分支作为长期监视的分支来控制代码品质。结论此次转型的好处是：每个版本的生命周期一目了然，同时可以随心所欲地把控指定的 commit 在指定的版本上发布，例如：在必须发布 patch 版本的时候，能有效避免主分支上的新功能的 commit 被提前发布（production 分支做不到这点）。再者，源代码的 Tag、Demo 网站、Wiki 文档，以及 gem 可以做到「四位一体」。个人觉得，GitLab Flow 的 release 分支模型配合 Git Flow 的 develop 分支，对个人开发者的开源项目来说是比较合适的。" }, { "title": "Docker 运行 Shadowsocks", "url": "/posts/steup-shadowsocks-with-docker/", "categories": "Tech, Shadowsocks", "tags": "shadowsocks, docker", "date": "2020-07-01 16:42:00 +0800", "snippet": "在更换一台新的梯子型 VPS 时，需要快速搭建 Shadowsocks，在运行 Linux 的 VPS 上采用 Docker 镜像安装将是个十分便捷的选择：无须考虑各种软件依赖对机器环境的污染（ Linux 跑服务不用 Docker 就是原罪）。虽然搭梯子频率很低，但在实施的时候，须翻阅好几个网站看文档，略烦。所以本文将略微讲述采用 Docker 搭建 Shadowsocks Server 的过程。安装 Docker Engine因为是裸机，所以安装 Docker Engine 是不能偷懒的，参考 Docker 官方文档 完成安装。出于本人的个人需要，下面将摘录在 Ubuntu Server 安装的步骤。配置 apt 仓库 为了允许服务器通过 HTTPS 拉取 Docker 仓库，需要更新 apt 索引以及安装所需的 packages: $ sudo apt-get update$ sudo apt-get install -y \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 添加 Docker 的 GPG key: $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 正确的指纹是 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88，通过后八位字符验证指纹: $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release (CE deb) &amp;lt;docker@docker.com&amp;gt; sub rsa4096 2017-02-22 [S] 添加 x86_64/amd64 仓库 $ sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; 安装更新索引再安装即可：$ sudo apt-get update$ sudo apt-get install -y docker-ce docker-ce-cli containerd.io验证是否正确安装，运行 hello-world 镜像：$ sudo docker run hello-world优化使用体验 为非 root 用户添加使用 Docker 的权限： $ sudo usermod -aG docker $USER$ newgrp docker 配置开机启动 Docker 以及 container： $ sudo systemctl enable docker.service$ sudo systemctl enable containerd.service 获取 Shadowsocks-libev 镜像安装好 Docker Engine 后，就可以进入正题了：$ docker pull shadowsocks/shadowsocks-libev默认会 pull 最新版本，需要指定旧版本可上 DockerHub 查询 Tags 列表。运行 Shadowsocks Server$ export passwd=&amp;lt;passwd&amp;gt; method=&amp;lt;encrypt_method&amp;gt; port=&amp;lt;server_port&amp;gt;$ docker run --name ssserver \\ -e PASSWORD=$passwd \\ -e METHOD=$method \\ -e SERVER_PORT=$port \\ -p $port:$port -p $port:$port/udp \\ -d --restart always shadowsocks/shadowsocks-libev把上述 &amp;lt;xxx&amp;gt; 部分参数替换为自己所需内容即可，详细参数说明可查看 GitHub 项目文档。最后，请确保 VPS 控制台为端口 port 开启 TCP/UDP 的入站出站过滤。" }, { "title": "对开源的一些体会", "url": "/posts/thoughts-on-open-source/", "categories": "Tech, Mix", "tags": "thoughts, story", "date": "2020-04-04 22:04:00 +0800", "snippet": "2020 年首文，四五个月没写过新文章，再不出一篇，博客都快要长草了。刚好昨天 Chirpy 项目拿到了第 100 个 star，所以踩点回忆一下将博客项目开源的初衷、过程中的体会以及对未来的一些想法。开源的初衷所有的故事的开始，都会出现一个不可逃避的问题，当时我面临的问题是，找不到自己想要的博客模版。另外，对前端技术觊觎已久却没有机会去接触实践，所以就从 2017 年末开始新建一个 Jekyll 项目，全新开发自己的博客。从第一行代码开始，博客项目在 GitHub 上一直保持开源的状态，原因有两个： 在 2019 年 1 月 之前，白嫖党不能把项目设置为私有。 白嫖党不能对私有项目启用 GitHub Pages 服务。第一个原因已消逝在历史长河，而第二个至今还在延续。起初我选择开源，完全是受丐帮精神的驱使，旨在把博客免费托管在 GitHub Pages 上。认真对待开源等到项目发展成熟到一定程度，开始觉得若只有自己一个人用，未免太过浪费劳动了，虽说设计和功能没有多么的惊艳，但是让后来玩 Jekyll 的人多一个选择也不是件坏事。于是在微软的扶贫济困以及某些不文明用户的推波助澜下，2019 年 1 月，我把博客的架构分离，使之成为一个开箱即用的模版项目。不过在 README 上只有草草几行字和一张预览图，对项目没有进行任何推广，代码设计也是以自己用的爽为标准，仿佛对外传递的态度是：爱用用，不用滚。这种状态维持大半年后，我开始对项目有了新的想法，假如有用户群，那么项目就可以得到不同类型、版本的浏览器和终端设备进行测试反馈，另外还可能得到其他开发者参与对项目的改进（思路或者修改源码都行）。那么，就必须要准备详尽的文档去指导别人在本地安装、运行项目。同年 8 月，项目新增了几个方便用户运行部署的工具脚本，另外还专门上线了一个的 Demo 站点 chirpy.cotes.info 供游客直接体验项目，文档也同步补全。这是一个转折点，不知不觉间，开始有了开源项目该有的样子。一旦资料齐全，某些汇集博客设计的平台就开始爬虫抓取项目信息了，如 jekyllthemes.dev 和 jekyll-themes.com 等，它们是自动并且免费的项目推广渠道，于是开始有了第一批的用户。随后的 9 月份，对项目 README 进行了严格标准化书写，浏览量也逐渐多了起来。随着 issue 的数量增多，为了节省时间，应景增加了 issue 模版。最后，对项目有实质改进的 PR 也出现了，其中一些 PR 对项目有了正向推动。至此，当初的小心愿全部达成。Star 与 Fork项目的 star 是每个开源项目作者都喜欢的东西，平时在技术论坛会遇到很多人发帖求 star，但是这个 star 的数量是不是和项目质量成正比呢？经过混在 GitHub 的日子看来，答案是否定的。GitHub 的 Explore repositories 经常推送一些项目，其中不少坐拥几百个 star，抱着学习心态点进去看，发现内容却是一言难尽，所以我对 star 的看法是：把它当作一种随缘的精神鼓励，实际上的作用是，可以增加项目在 GitHub 上的曝光率。另一方面，对于 fork，通过观察派生的子树项目可以洞悉用户的使用习惯，以及他们会遇到的阻碍，进而改进项目工具脚本以及文档。遇到的一些事开源遇到的第一件事情是：来自别人的提问。有疑问是正常的，项目文档可以帮助用户自我排查问题，省去提问的环节，对用户和作者双方来说都可以省下可观的时间和精力。因此，我尽可能的把所有安装使用细节写在 README 或者 Demo 网站上。然而，偏偏是有那么一群人，不屑文档的存在，或者不曾尝试自行去思考、搜索答案，把开源作者当人工服务专线：一个劲的发邮件私信或者 issue，甚至有的还要求加社交 APP 一对一辅导解答，真是喵了个咪了。一开始还能心平气和地应对，后来次数多了，不堪其扰，对这类情况处理的方式逐渐变得果断高效：邮件私信提此类问题的一律怒删；跑到 GitHub issue 留下无脑提问的，一律加上标签 RTFM 教做人。作为伸手党不看文档瞎提问，缺失最基本道德标准和人文素养，那么休怪我无情了。人生苦短，不值得为这些琐碎事浪费时间。接着，还会发现有些「人才」喜欢悄悄拿走项目，然后删掉源码文件头部版权声明。博客项目基于 MIT 协议开源，允许改为私用没有问题，可是删出处声明这也太恶心了，MIT 协议是限制要求保留原项目 LICENSE 的。即使被删地址改名称，但如果我想找出来，还是很容易的。声明一下，有这类奇葩行为的用户不限某一地区或国家，本人不针对特定的文化背景或者地域的人，吐槽的是行为，对事不对人。除去上述种种怪象，开源社区本质上仍旧是一个充满阳光和爱心的地方。譬如，项目不定期收到「谢谢分享」之类的留言，对作者就是莫大的精神鼓励，还有就是很开心看到用户们在此基础上部署自己的博客，然后分享他们在各自领域上耕耘的成果，促进了互联网的知识分享和流通，这难道不是博客项目开源的最大价值吗？最后，讨论一下打赏（网络乞讨）。事情是这样发生的：某天醒来，我收到一条暖心留言说要为项目打赏，但随后下意识地婉拒了。当时我认为开源意味着免费提供使用，无须和金钱挂钩。过了一段时间，无意间看了一些国外开源大佬对打赏文化的解读，才逐渐了解到：开源接受打赏未尝不可，因为打赏是用户对作者表达感谢的一种方式，这个渠道不应该被强行阻断。其次，平心而论，项目的开发及运营必定会占用开发者的私人时间，而时间就是金钱，打赏可以补偿一下开源作者的时间的损失，或者运营的成本支出，使其能够更好地投入开发，保持开源社区的良性发展。一番考虑过后，只好含泪把讨饭链接贴在 GitHub 项目里面了。未来的计划将来如果有其他新的想法，觉得有复用的价值就会开源出来，但是不会公开那些实验性质或者没复用价值的项目，毕竟保障开源项目质量人人有责。再说句题外话凑字数：当下 COVID-19 全球扩散，希望健康的人们疾疫不临，感染者早日康复，逝者的灵魂可以安息。" }, { "title": "MacBook 合盖自动关闭蓝牙", "url": "/posts/turn-off-bluetooth-when-macbook-sleeps/", "categories": "Tech, Mac", "tags": "blueutil, sleepwatcher, homebrew, macos", "date": "2019-11-08 13:31:00 +0800", "snippet": "用过 MacBook 系列产品的童鞋应该都会发现，在合盖之后，蓝牙进程还是在后台处于开启状态。这对于限制链接数的蓝牙设备就会造成名额占位。例如，本人手上的某款蓝牙耳机，限制最多接入两个音源设备，MacBook 上用蓝牙耳机听着音乐，同时平板也保持和耳机的链接，几分钟后完成手上工作，合盖 Mac 潇洒离座，然后手插裤兜掏出手机想用蓝牙耳机听歌，这时耳机链接名额已经给平板和 Mac 占满了，无法再接纳手机。因此就不得不灰溜溜地归位，手动关闭平板或者 Mac 对耳机的链接。耗电与否先不讨论，蓝牙耳机的使用体验上已经大打折扣了。如果可以改变 MacBook 的习性，让它合盖之后自动关闭蓝牙，就不用手动释放对蓝牙设备的占用了。So, 果断开工让 MacBook 成为更聪明的宝宝！CLI 关闭蓝牙blueutil 是 Mac 上的控制蓝牙的命令行工具，可以检查蓝牙状态，以及开启/关闭等操作。通过 Homebrew 安装十分方便：$ brew install blueutil关闭蓝牙：$ blueutil -p 0开启蓝牙：$ blueutil -p 1短短的命令就可以轻松 开/关 蓝牙，这时候只需要把上述 CLI 加入 合盖/开盖 监视器即可。监测休眠及唤醒sleepwatcher 可以监测 Mac 的休眠唤醒以及空闲状态，并执行用户自指定的命令。通过 Homebrew 获得：$ brew install sleepwatcher系统自启动 sleepwatcher 后台进程，过程需要 Administrator 密码开启权限：$ brew services start sleepwatcher==&amp;gt; Successfully started **sleepwatcher** (label: homebrew.mxcl.sleepwatcher)执行完毕可以检查后台进程是否添加成功：$ brew services listName Status User Plistsleepwatcher started Cotes /Users/cotes/Library/LaunchAgents/homebrew.mxcl.sleepwatcher.plist$ ps aux | grep sleepwatcherCotes 3067 0.0 0.0 4317336 4552 ?? S 7:39PM 0:01.79 /usr/local/sbin/sleepwatcher -V -s ~/.sleep -w ~/.wakeup从输出看到 sleepwatcher 已经成功进驻后台进程列表。-s 的参数指定监测的休眠指令存放于~/.sleep，-w 指定监测的唤醒指令存放于 ~/.wakeup，接下来把蓝牙开关的命令加入这两个文件即可。指定合盖（休眠）执行蓝牙关闭：$ echo &quot;$(which blueutil) -p 0&quot; &amp;gt;&amp;gt; ~/.sleep 注：which 是为了指定 CLI 的绝对路径。接着，添加开盖（唤醒）自动开启蓝牙，并且自动连上蓝牙设备：$ echo &quot;$(which blueutil) -p 1 &amp;amp;&amp;amp; $(which blueutil) --connect DEVICE_NAME&quot; &amp;gt;&amp;gt; ~/.wakeup把 DEVICE_NAME 更换为你的蓝牙设备名称。若你不知道设备名称，可通过以下命令获得：$ blueutil --pairedaddress: 4e-21-f2-b1-a5-67, not connected, not favourite, paired, name: &quot;Headphone&quot;, recent access date: 2020-03-23 21:25:48 +0000输出日志的 name 部分就是设备的名字。最后，为命令文件添加执行权：$ chmod +x ~/.sleep ~/.wakeupOK，一切完毕，自动开闭蓝牙真心爽。不吹不黑，sleepwatcher 是个好东西，日后必另作他用。参考 Mac OS X: Automating Tasks on Sleep" }, { "title": "GitHub Pages 的暗礁", "url": "/posts/solving-gh-pages-is-not-built-automatically/", "categories": "Tech, Website", "tags": "github pages, github api", "date": "2019-08-13 12:04:00 +0800", "snippet": "距离博客的框架设计分离出来成为一个独立项目，已经过去一段时间了，所以想把框架项目变成更加纯粹的 Jekyll Theme，项目名称也改为了 Chirpy，为项目部署一个新的 Demo 站点也是水到渠成的事。那么主题项目 Chirpy（也就是博客的架构）的 Travis-CI 流程要在原来础上增加一个步骤：部署到 Chirpy 的 Demo 站点。合并下来，Chirpy 线上 CI 的工作流就变成： 部署主题 Demo 部署个人博客GitHub Pages 掉链子本来一切看起来十分清晰流畅，然而 GitHub Pages 却不甘心让部署变得如此平凡。在一个 Travis-CI build 里推送更新到上述两个 GitHub 仓库，后一个仓库（博客仓库）的 Pages 内容并不会更新。先来分析一下问题：博客仓存放的内容是静态文件，无需 GitHub 编译构建，所以不会存在构建错误的问题，而且前后 GitHub 也没有发送任何错误提示的邮件。接着，追溯到仓库文件，Commit 记录显示文件已更新到最新版本。那么就只有一个可能：GitHub Pages 服务器没有按照仓库文件的更新的内容去重新构建站点。GitHub 网页上的 Commit 记录证明了这个推断，最新的 Commit 没有被 Pages 构建。这时我想也许是因为太多用户使用 Pages 服务，导致服务器构建队列拥挤，产生延时。结果耐心等了一个小时，还是不会有任何变化：经过 Pages 构建的 Commit 记录是这样的，会有个绿色的小钩：进一步试验后发现，单独更新博客仓库是可以触发 Pages 刷新的，唯独在同一时间段（间隔很短，几秒钟之内）更新名下的两个 Pages 仓库，就会出现后一个不被构建的问题。是不是 GitHub 有限制机制呢？就这个问题，我向 GitHub 客服反馈了两次，而客服作为代理人，需要将问题反馈到工程师团队，在内部完成问题追踪后才有答案。因为不想干等，所以我选择亲自出手解决。API 救场为了拯救被遗忘的构建，可以通过 GitHub Pages API 1 去触发指定仓库的 Pages 构建。通过 curl 发送 POST 请求：$ curl -H &quot;Authorization: token &amp;lt;GH_TOKEN&amp;gt;&quot; \\ -H &quot;Accept: application/vnd.github.mister-fantastic-preview+json&quot; \\ -X POST https://api.github.com/repos/&amp;lt;USERNAME&amp;gt;/&amp;lt;REPO&amp;gt;/pages/builds其中 GH_TOKEN 来自 GitHub 账户的 Personal access tokens ，下文相同。这样就不用去 GitHub 网页上傻傻的检查部署了。进一步细化上述提到，相同时间内推送更新若干个 Pages 仓库文件，第一个仓库总是可以正常触发 Pages 构建的，所以应该添加一层检查机制，不必每个仓库都发送指令。先观察仓库是否按照最新 Commit 被自动构建，如果不是，才需要 API 发起构建。GitHub Pages 可以通过 API 查询仓库最新的 Pages 构建状态2，通过 curl 发送 GET 请求：$ curl -H &quot;Authorization: token &amp;lt;GH_TOKEN&amp;gt;&quot; \\ https://api.github.com/repos/&amp;lt;USERNAME&amp;gt;/&amp;lt;REPO&amp;gt;/pages/builds/latest以本站仓库为例，响应内容如下：{ &quot;url&quot;: &quot;https://api.github.com/repos/cotes2020/cotes2020.github.io/pages/builds/140717683&quot;, &quot;status&quot;: &quot;built&quot;, &quot;error&quot;: { &quot;message&quot;: null }, &quot;pusher&quot;: { &quot;login&quot;: &quot;cotes2020&quot;, &quot;id&quot;: 11503861, &quot;node_id&quot;: &quot;MDQ6WXNlcjExMxcxMzQw&quot;, &quot;avatar_url&quot;: &quot;https://avatars0.githubusercontent.com/u/11502841?v=4&quot;, &quot;gravatar_id&quot;: &quot;&quot;, &quot;url&quot;: &quot;https://api.github.com/users/cotes2020&quot;, &quot;html_url&quot;: &quot;https://github.com/cotes2020&quot;, &quot;followers_url&quot;: &quot;https://api.github.com/users/cotes2020/followers&quot;, &quot;following_url&quot;: &quot;https://api.github.com/users/cotes2020/following{/other_user}&quot;, &quot;gists_url&quot;: &quot;https://api.github.com/users/cotes2020/gists{/gist_id}&quot;, &quot;starred_url&quot;: &quot;https://api.github.com/users/cotes2020/starred{/owner}{/repo}&quot;, &quot;subscriptions_url&quot;: &quot;https://api.github.com/users/cotes2020/subscriptions&quot;, &quot;organizations_url&quot;: &quot;https://api.github.com/users/cotes2020/orgs&quot;, &quot;repos_url&quot;: &quot;https://api.github.com/users/cotes2020/repos&quot;, &quot;events_url&quot;: &quot;https://api.github.com/users/cotes2020/events{/privacy}&quot;, &quot;received_events_url&quot;: &quot;https://api.github.com/users/cotes2020/received_events&quot;, &quot;type&quot;: &quot;User&quot;, &quot;site_admin&quot;: false }, &quot;commit&quot;: &quot;196791a3b4026178807b70f93cdb189c6bffad74&quot;, &quot;duration&quot;: 29445, &quot;created_at&quot;: &quot;2019-08-12T15:21:01Z&quot;, &quot;updated_at&quot;: &quot;2019-08-12T15:21:31Z&quot;}需要关注的是 status 和 commit： &quot;status&quot;: &quot;built&quot; 表示站点构建已经完成。 &quot;commit&quot;: &quot;196791a...&quot; 表示站点是依照 196791a... 这个版本的文件去构建的。掌握这些信息后，只要在 status: built 的状态下，检查 Pages 最后构建的 commit 和仓库最后一个 commit 的 SHA-1，如果不相同，就可以确定构建没有启动，需要 API 发送指令触发构建，bash 版的实现逻辑如下：sleep 10 # Wait 10 seconds, let GitHub Pages go firstif [[ $status == &#39;built&#39; &amp;amp;&amp;amp; $repo_last_commit != $pages_commit ]]; then # Send build request to GitHub Pagesfi先休眠 10 秒，是为了给 GitHub Pages 留出启动时间。通过调用 GitHub Pages API 可以确保自动化部署的站点页面得到实时更新，但是心中依然对 GitHub 在处理多个仓库同时更新时出现的必然性遗漏表示不解。迟来的回应（2019-08-30 更新）经历大半个月，前天 (Aug 28, 1:34 AM UTC) GitHub Developer Support 终于发来一封邮件给出实质性答复： The trouble you’re facing is due to a limitation in GitHub Pages, with regard to parallel builds triggered by a single user account. Due to certain technical limitations, we can only successfully process one site build at a time, per user account. Our engineers are working to remove this limitation, but we can’t promise if or when this work will be completed. As your setup involves pushing to (and thus triggering builds for) more than one repository at a time, this can result in some build requests colliding, stalling, and silently failing.根据上述回应，证明了我的猜想，这是 GitHub Pages 服务器对并行构建实施了限制，另外还提到工程师准备去掉这个限制，但是不保证何时完成。接着邮件中还给出解决建议： To avoid this trouble, I’d suggest adding a delay to your automation process, such that the repositories are pushed in sequence, rather than in parallel. You could use a simple delay of a couple of minutes to achieve this, but a most deterministic approach would be to listen for PageBuildEvent, which will only be returned once a build has completed: https://developer.github.com/v3/activity/events/types/#pagebuildevent基本和我之前的解决方案一样，用 API 精确检测 GitHub Pages build 的状态，但其实还是可以把处理流程改的更贴合官方的建议：先等待前一个 GitHub Pages 构建完成了（经过实测，静态页面仓库可以在 20 秒以内完成构建），再推送下一个仓库，这样就省去发送 API 触发构建的那一步。总结从 8 月 16 日 到 28 日这十来天没有收到任何回应，感觉 GitHub 就打算这样不了了之，而我也做好心理准备了，反正已经琢磨出解决方案了。可后来官方对我等免费用户不放弃的态度，着实令人感动。接下来，就是坐等 GitHub Pages 服务器正式解除并行推送的限制，可以让项目的 CI 代码再精简几行。参考资料 GitHub REST API v3: Pages &amp;#8617; Stackoverflow: How do I check the deploy status of Github Pages? &amp;#8617; " }, { "title": "Homebrew 替换国内源", "url": "/posts/replace-cn-mirror-for-homebrew/", "categories": "Tech, Mac", "tags": "macos, homebrew", "date": "2019-07-11 16:48:00 +0800", "snippet": "Homebrew 默认 GitHub 源的拉取速度慢得令人发指，以至于知乎出现了一个令人鼻酸的回答：为了对抗不公，必须使用国内镜像加速 Homebrew 的速度。中科大和清华两家的源做的很不错（此外还有 coding.net 的可选），下面介绍替换中科大的源。更换源代码仓库替换主仓库：$ git -C &quot;$(brew --repo)&quot; remote set-url origin https://mirrors.ustc.edu.cn/brew.git &amp;amp;&amp;amp; git pull origin master替换 homebrew-core 仓库：$ git -C &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot; remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git &amp;amp;&amp;amp; git pull origin master替换 homebrew-cask 仓库:$ git -C &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-cask&quot; remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.git &amp;amp;&amp;amp; git pull origin master更换 Homebrew Bottles 源:$ echo &#39;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&#39; &amp;gt;&amp;gt; ~/.bash_profile$ source ~/.bash_profile完毕后，执行更新与升级：$ brew update &amp;amp;&amp;amp; brew upgrade恢复官方配置某些情况下，譬如肉身翻墙了，可能需要换回官方的 GitHub 源：$ git -C &quot;$(brew --repo)&quot; remote set-url origin https://github.com/Homebrew/brew.git$ git -C &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot; remote set-url origin https://github.com/Homebrew/homebrew-core.git$ git -C &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-cask&quot; remote set-url origin https://github.com/Homebrew/homebrew-cask.git另外，在 ~/.bash_profile 中去除环境变量 HOMEBREW_BOTTLE_DOMAIN，也就是 更换 Homebrew Bottles 源 的逆向操作:$ sed -i &quot;/HOMEBREW_BOTTLE_DOMAIN/d&quot; ~/.bash_profile &amp;amp;&amp;amp; source ~/.bash_profile参考资料 LUG@USTC：Homebrew 源使用帮助 知乎：Homebrew 有比较快的源 (mirror) 吗？" }, { "title": "macOS 使用 GNU 命令", "url": "/posts/use-gnu-utilities-in-mac/", "categories": "Tech, Mac", "tags": "macos, homebrew, gnu", "date": "2019-07-11 01:36:00 +0800", "snippet": "macOS 的自带命令行工具是 BSD 版本的，要想在 Mac 上开发可以完美运行在 GNU/Linux 上的 Shell 脚本，就必须依赖 Linux 服务器，或者本地 Linux VM / Docker 去测试脚本，甚是麻烦。如果将命令行工具从 BSD 版本替换为 GNU 版本，把 Mac 当做 Linux 来用（不包括内核部分），将会意义非凡。本文将会介绍替换的原理与方法。安装 GNU 工具所需的 GNU 工具可通过 Homebrew 安装，常用工具的安装如下:$ brew install coreutils$ brew install findutils$ brew install gnu-sed$ brew install gnu-indent$ brew install gnu-tar$ brew install gnu-which$ brew install gnutls$ brew install grep$ brew install gzip$ brew install screen$ brew install watch$ brew install wdiff --with-gettext$ brew install wget$ brew install less$ brew install unzip如需要搜索所有 GNU 工具列表，可以通过以下命令获得：$ brew search gnu覆盖系统自带命令Homebrew 安装的命令工具默认放置在 /usr/local/opt/，而系统自带 BSD 工具的路径为 /usr/bin/。当安装的 GNU 命令与系统自带命令重复时，用前缀 g 可以指定使用 GNU 版本，如：$ gsed # 使用 GNU 版本的 sed (gnu-sed)$ sed # 使用 BSD 版的 sed如果想省去 g 前缀，在环境变量 PATH 中把 GNU 工具的执行路径放置于 /usr/bin 之前即可（在安装命令工具的时候，输出日志就有指示）。原理是在系统扫描可执行路径时，会使用第一个符合条件的值：export PATH=&quot;/usr/local/opt/&amp;lt;PACKAGE&amp;gt;/libexec/gnubin:$PATH&quot;上述 PACKAGE 为工具包名称。对应上文「安装 GNU 命令工具」里提及的工具，在文件 ~/.zshrc （若使用 Bash，则为 ~/.bash_profile） 添加以下指令以实现对系统默认工具的覆盖:export PATH=&quot;/usr/local/opt/coreutils/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-sed/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/binutils/bin:$PATH&quot;export PATH=&quot;/usr/local/opt/ed/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/findutils/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-indent/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-tar/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-which/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/grep/libexec/gnubin:$PATH&quot;刷新使其生效：$ source ~/.zshrc在 BSD 与 GNU 之间切换如果你因为临时业务需求，或者觉得花大价钱买来的 Mac 不用太浪费，想换回 BSD 环境时，那么可以暂时屏蔽相关的 GNU 的执行路径：# export PATH=&quot;/usr/local/opt/&amp;lt;PACKAGE&amp;gt;/libexec/gnubin:$PATH&quot;聪明的你也许发现了，上述例子要手动屏蔽的内容多达 9 行，而且之后恢复 GNU 还得一条条去掉注释符号 #，是时候要想个办法偷懒了。可考考虑在 ~/.zshrc (或 ~/.bash_profile) 添加自定义函数进行切换：gnu_utils=( PACKAGE # the other utils ...)gnu() { for _util in &quot;${gnu_utils[@]}&quot;; do export PATH=&quot;/usr/local/opt/$_util/libexec/gnubin:$PATH&quot; done [[ $1 == &quot;--quiet&quot; ]] || echo &quot;Switched to GNU utils!&quot;}bsd() { for _util in &quot;${gnu_utils[@]}&quot;; do export PATH=&quot;$(echo $PATH | sed &quot;s|/usr/local/opt/$_util/libexec/gnubin:||&quot;)&quot; done echo &quot;Switched to BSD utils!&quot;}gnu --quiet添加完成后运行 source ~/.zshrc 或重启终端使函数生效。上述命令很简单：gnu() 把 GNU 工具的执行路径插入环境变量 PATH，而 bsd() 负责从 PATH 里面清除 GNU 的执行路径。因为需要在终端启动时默认使用 GNU，在上段代码结尾调用了 gnu。以后切换命令工具的版本时，在终端直接指定期望的工具名称即可： 切换到 GNU 工具： $ gnuSwitched to GNU utils! 切换到 BSD 工具： $ bsdSwitched to BSD utils! 现在，Mac 可以当作是换皮 Linux 来写脚本了，性价比再加一分。参考资料 Install and Use GNU Command Line Tools on macOS/OS X How to replace Mac OS X utilities with GNU core utilities?" }, { "title": "TXT 制作 MOBI", "url": "/posts/convert-txt-to-mobi/", "categories": "Living, Kindle", "tags": "kindle", "date": "2019-05-09 21:44:00 +0800", "snippet": "概述本文将会介绍如何把 TXT 文件制作成为 Kindle 的 MOBI 文件。工具事先备好如下两项工具： 文本编辑器 Calibre 3.42.0其中文本编辑器选择自己熟悉的，并且支持正则表达式的产品。如 Sublime Text, Notepad++ 等。TXT 修订TXT 文件的段落章节使用 Markdown 语法添加目录，如原文：第 &amp;lt;一|二|...&amp;gt; 章修改为 Markdown 的 H2 标题：## 第 &amp;lt;一|二|...&amp;gt; 章由于手动修改费时费力，因此可以考虑用正则表达式完成。常用的正则表达式 搜索规则 替换为 备注 ^第(.)章 ##第\\1章 添加H2标题 ,\\n\\s* , 修正 , 异常换行 具体修订细节需要针对实际的内容而定，不可一概而论。Calibre 转换开始转换之前，先为 Calibre 完成一些全局的基本配置。 注：本文使用的是 Mac 版 Calibre ，Windows 版的软件界面会有细节差异。Common options进入 Calibre 的 Preferences → Common options：选择 Look &amp;amp; feel：Layout 设置如下：Styling 添加 CSS：h2 { padding: 1.25em 0}p { line-height: 1.8em }其次，切换到 Page setup → Out profile 选择自己的 Kindle 设备型号。然后切换到 Table of Contents，设置一二级目录：Output Options进入 Calibre 的 Preferences → Output options:MOBI ouput → MOBI file type: 选择 both。这里表示输出 MOBI 会混和 KF6 和 KF8 格式，上述的自定义 CSS 才会生效。若保持默认为 old，则会被忽略自定义样式。若选择 new，在 Kindle 上却不能打开生成的 MOBI。完成上述设置后保存修改即可。制作 MOBIAdd books 导入准备好的 TXT 文件，Convert books 修改 Metadata，譬如作者信息、出版社、封面图片等。封面问题按照上述步骤制作的 MOBI 文件，如果在 Calibre 通过 USB 连接发送到 Kindle，是可以在设备上看到封面图片的。但是，如果是邮件推送到 Amazon 的个人文档存储，再下载到 Kindle 阅读器就不能显示封面（iOS 版的 Kindle App 可以显示）。所以，目前来说，阅读器显示封面和云端存储只能二选一。参考文献 把 TXT 文档转换成带目录的 MOBI 格式电子书 Calibre 和 Kindle 配合的使用方法" }, { "title": "士力架的规格与差价", "url": "/posts/pricing-rules-for-snickers/", "categories": "Living, Discovery", "tags": "foods", "date": "2019-03-25 21:00:00 +0800", "snippet": "有时候，在屋子里难免会觉得饥饿难耐，就算点外卖，肚子也得咕噜叫个半个钟或更久。这时候，救火型的快速充饥食品就很重要了。在附近沃尔玛超市里面，买过各种各样的小包装糕点、奥利奥、沙琪玛之类的，还有好时醇黑巧克力，最后还是觉得，士力架比较耐饿，虽然很甜，吃的时候小口吃，配白开水送就没问题了。买了几次，发现超市货架上出售的士力架有几种不同的包装，而且性价比也各有不同。桶装纸盒装下面进行性价比分析： 净含量 价格 性价比 桶装 460g ¥ 29.80 15.44 g/¥ 纸盒 239g ¥ 13.80 17.32 g/¥ 桶装的每小包净重 20 克，纸盒装的每小包净重 51 克。性价比上，纸盒装的 17 克/元，桶装的 15 克/元，高下立判，所以选购的都是纸盒装的。两种规格配料都是一样的，内部分别是花生和软焦糖夹层，再用可可浆包裹外层。为何包装越小的，每克的标价越高呢？咋看是食品厂商耍小心机，但是今天忽然灵光一闪，意识到这是一个关于面积和体积比的问题，物体的体积越小，表面积相对越大，需要的可可液涂层就越多了。所以此后选择不同包装就可以释怀了：喜欢吃多点巧克力层，就买小包装的，喜欢吃多点内层花生焦糖，就买长条装的。" }, { "title": "博客架构分拆", "url": "/posts/split-posts-n-metadata-of-blog/", "categories": "Tech, Website", "tags": "story, jekyll, travis ci, github", "date": "2019-01-14 22:01:00 +0800", "snippet": "令人瑟瑟发抖的寒冬中，时间迈入了 2019 年。一片萧条的大环境下，人们注定要为今后的生活付出更多艰辛与努力。微软，大洋彼岸的 IT 巨头，似乎觉察到这点，于是大手一挥送温暖：于今年 1 月 8 日宣告 GitHub 对个人开发者免费提供私密仓库服务，数量无限制。要知道，此前私密仓库是要每月耗费 7 刀巨资啊。收到这份新禧礼物后，我激动地把分散到各处小作坊平台的仓库统一迁移到 GitHub 上，逛 GitHub 的频率随之陡增。就是在这样的背景下，发现 GitHub 有人 Fork 我的博客仓库。像本站这种不走量不推广，且国内不备案的边缘博客，理论上没人关注的，于是好奇地进到那货的 GitHub 主页，一看 ID 是新注册的，而且每天大批量的搜索 GitHub 并 Fork 开源的仓库，一天几十上百的 Fork，典型的自动化脚本操作。没图你会说我吹牛逼，下面就是那个账户的异常活动：既然我把博客仓库开源了，自然没有什么敏感数据在上面。不过对于这种扫库行为，心里依然略有芥蒂，于是微微一笑，把那个马甲账户 Block 了。一个小思考这件趣事也引发了我的一个思考，如果某个项目真的存在一些敏感数据，怎样在保证开源的情况下隐藏这些数据呢？在梦中我找到了答案：把项目的仓库分拆。基础框架和敏感数据拆分，后者移出到新的私有仓库，刚好可以合理用上 GitHub 无限免费私仓服务。借助这个思路，顺便可以把文章和博客框架也分拆开，包括需要隐藏的元数据（Google-ID, Disqus 等）在内，可以把原始仓库分成三部分: Framework Posts Meta拆分细节 Framework 作为通用模版而存在，方便别人对本站架构进行复用（虽然可能性约等于零），进一步贴近开源精神。 Posts 主要是文字创作内容，这可以很好的把 post 的更新记录从站点架构中分离出来，使两边的提交历史更加清晰明了。 Meta 对外透明，定义那些高度私人化、零复用价值的数据，即便这样，编译后的静态文件还是包含了这些数据，隐藏起来只是为了满足心里的仪式感，正所谓防君子不防小人。工作流变化分拆是个双刃剑，方便了内容管理，也给本地开发和线上的 CI 产生了阻力。为了解决这两个问题，我的解决方案如下： 更新基础架构或者修改文章后，用脚本把三个零散仓库通过拷贝合并起来，成为一个完整的项目，再进行构建和测试。 持续集成可以由 Framework 和 Posts 两个仓库触发。 Travis CI 的只对公开仓库提供免费服务，所以 Meta 私有仓库是不能够触发线上 CI 的，必要时，可以到 Travis CI 上手动触发 Framework 或 Posts 的构建，即可把 Meta 的更新进行部署。由于此部分内容更新频率极低，所以影响不大。后话分拆的作业看着简单，但是耗费了整整一天。仓库内容分离以及 Travis CI 的脚本修改需要点耐心。最后顺利成功了，自然也是小有成就感，博客的项目演进又往前迈进了一小步。" }, { "title": "Jekyll 集成 Travis CI", "url": "/posts/integrate-travis-ci-in-jekyll/", "categories": "Tech, Website", "tags": "travis ci, jekyll", "date": "2018-11-08 22:17:00 +0800", "snippet": "前段时间，因为本地 git push -f 覆盖远端 master 分支，导致博客在 GitHub Pages 上编译失败。查看 GitHub Help 的文档 “Viewing Jekyll build error messages”，文中提及可以通过第三方平台执行 build，直接观察错误信息细节，这才开始认识了本文主角：Travis CI。Travis CI 是个提供持续集成的服务平台，对 GitHub 开源项目免费，它可以自定义配置编译、测试到发布全套流程。如果只用来观察编译的日志，实在太浪费了。在此之前，本站项目推送到 GitHub 之前，都会先干两件事： 检查每篇文章的最后更新时间 生成所有 Category 和 Tag 的独立页面第一点「文章更新时间」可以用第三方 Jekyll 插件实现。直接推送 Jekyll 项目源码到仓库根目录，是由 GitHub Pages 执行构建，但它启用了 --safe 选项，第三方的 Jekyll Plugins 是不允许运行的，所以笔者写了 Python 脚本去完成这两个初始化工作，每次写完文章执行 commit 之后，本地运行一下初始化脚本，然后 push 到远端。初始化脚本会对本地硬盘进行 I/O 操作，理论上会损耗硬件寿命：Mac 价格逐年创新，必须加倍疼爱手上的机器。现在看来，将这两任项务交给 Travis CI，那是再合适不过了。 注：Travis CI 只对 GitHub 上的项目提供 CI 服务，其他代码托管平台只能移步。经过进一步的考究，GitHub Pages 支持静态文件托管，因此可以把站点构建生成的静态站点文件（_site 的内容）放到一个空白仓库中，由它开启 Pages 服务即可。站点构建托付给 Travis CI，绕开 GitHub Pages，这意味着可以任意使用第三方 Jekyll Plugins。最后，项目源码和发布的静态资源分成两个仓库管理，最初的代码库仓库 USER.github.io 可以不受约束改成自己喜欢的名字，而且代码库的 master 分支也解放出来了（ GitHub Pages 强制占用 User and Organization Pages sites 的 master 分支）。所以改造工程将包含： 项目源码和项目部署分仓 源码仓库集成 Travis CI GitHub 授权 Travis CI 开启服务GitHub 分仓Step 1. 在 GitHub 上把 USER.github.io 仓库重命名为 USER-blog，用于存放源码。Step 2. 本地 Git 配置要做更改:$ cd /path/to/repository$ git remote set-url origin git@github.com:USER/USER-blog.git$ git remote set-url --push origin git@github.com:USER/USER-blog.git上述命令把本地 git 的 fetch 和 push 远程地址修改为新库地址，USER 为 GitHub 用户名。Step 3. GitHub 新建仓库 USER.github.io，没有错，替代 Step 1 的旧仓库名称，用于存放构建输出的静态文件。切记为这个仓库开启 Pages 服务。下面详细介绍源码仓库 USER-blog 接入 Travis CI 的步骤。Jekyll 配置Gemfile因为在 CI 中会用 Bundler 编译项目，所以要确保项目根目录包含一个 Gemfile 文件, 没有则新建，首行内容如下：source &quot;https://rubygems.org&quot;项目中依赖的 Jekyll Plugins，在 Gemfile 中添加依赖声明:group :jekyll_plugins do gem &quot;plugin-a&quot; gem &quot;plugin-b&quot; # ...end 注: 如果插件没有声明在 :jekyll_plugins 分组内，则需要在 _config.yml 的 plugins 数组再次引用，即： # Gemfilegem &quot;plugin-x&quot;# _config.ymlplugins: - plugin-x 笔者 Gemfile 全部配置如下：source &quot;https://rubygems.org&quot;group :jekyll_plugins do gem &quot;jekyll-paginate&quot; gem &quot;jekyll-feed&quot;, &quot;~&amp;gt; 0.6&quot; gem &quot;jekyll-redirect-from&quot; gem &quot;jekyll-last-modified-at&quot; # 3rd-party pluginsend# Windows does not include zoneinfo files, so bundle the tzinfo-data gemgem &#39;tzinfo-data&#39;, platforms: [:mingw, :mswin, :x64_mingw, :jruby]_config.yml_config.yml 中若没有显式声明 exclude，以下文件列表会从默认构建中略过：exclude: - Gemfile - Gemfile.lock - node_modules - vendor/bundle/ - vendor/cache/ - vendor/gems/ - vendor/ruby/但是如果自定义了 exclude 覆盖默认列表，则确保要包含：exclude: vendor因为 Travis 容器默认构建命令为：$ bundle install --deployment # some other args ...其中 --deployment 参数会将 gems 包存放在当前路径的 vendor 目录之下。另外，自定义的 exclude 列表，也应包含对站点无用的其他工程文件:exclude: - Gemfile - Gemfile.lock - README.md.travis.yml项目根目录建一个文件，命名为 .travis.yml，有了它 Travis 才会自动对项目进行抓取编译等工作。笔者配置如下：os: linuxdist: bioniclanguage: rubyrvm: 2.6cache: Bundler # speed up the build by using bundler cachebefore_install: - pip install --upgrade pip # Travis CI asked for it. - pip install ruamel.yamlscript: bash ./scripts/cibuild.shbranches: only: masternotifications: email: recipients: - secure: ENCRYPT_EMAIL_ADDRESS_STRING on_success: neverenv: global: - secure: ENCRYPT_KEY_VALUE_PAIRE上述配置首先 language 和 rvm 描述了 Travis 虚拟机中的主语言环境。接着执行流程是：install → script。install 部分安装了 Jekyll 环境和后面脚本需要的 Python 依赖。script 声明了 Travis 应该执行命令。特别说明一下 env.global 的内容，里面是一个 Travis 客户端加密后的 GitHub Token 键值对。cibuild.sh 中的向 GitHub 推送代码需要用这个 token 来通过 GitHub 的权限认证。GitHub TokenGitHub Token 申请可访问设置页面新建，Select scopes 部分选取 repo 的全部权限。这个 token 十分重要，如果不想让人在自己仓库涂鸦，须谨慎保存。Travis Web 提供Envrionmen 变量的加密存储，为了减少网上泄漏的风险，还是建议自己本地加密，再将加密串写入 .travis.yml。本地安装 Travis Client，执行加密：$ cd /path/to/repository$ travis encrypt GITHUB_TOKEN=&amp;lt;your-github-access-token&amp;gt; 注: 上述命令命令末端加 --add 指令，加密结果会自动添加到 .travis.yml 文件末尾的 env.global。将加密结果拷贝到 .travis.yml 的 env.global 下，用 secure 表明是一个加密字符串。笔者用这个方式还加密了build结果通知的邮件地址。Coding Token（可选）如果想同时部署到 Coding Pages，则还要建立一个 Coding 的 Token，官方称作「访问牌令」，创建入口在 Coding 的个人账户即可找到：界面几乎是 GitHub 的中文版，选择权限 部分选取 project:depot。Travis 加密获得的 token 同样也是安全敏感数据，采用本地 Travis-Cli 加密，存入 env.global 即可：env: global: - secure: &quot;yHH2GnrRs6aUmqu4t7dRV8L...&quot; # GitHub token - secure: &quot;RTg3SeugMzxrkzfLBU8zHpa...&quot; # Coding tokencibuild.shscript 部分执行脚本 cibuild.sh，Travis 构建和部署的核心逻辑就定义在此。内容如下：#!/bin/bashGITHUB_DEPOLY=https://${GITHUB_TOKEN}@github.com/cotes2020/cotes2020.github.io.gitCODING_DEPOLY=https://cotes:${CODING_TOKEN}@git.dev.tencent.com/cotes/cotes.coding.me.git# skip if build is triggered by pull requestif [ $TRAVIS_PULL_REQUEST != &quot;false&quot; ]; then echo &quot;this is PR, exiting&quot; exit 0fi# enable error reporting to the consoleset -eif [ -d &quot;_site&quot; ]; then rm -rf _sitefi## Check lasmod of posts and the Category, Tag pages.export TZ=&#39;Asia/Shanghai&#39; # the lastmod detection needs thisecho &quot;date: $(date)&quot;python ./scripts/pages_generator.py# build Jekyll ouput to directory ./_siteJEKYLL_ENV=production bundle exec jekyll build## Git settingsgit config --global user.email &quot;travis@travis-ci.org&quot;git config --global user.name &quot;Travis-CI&quot;DEPOLYS=(${GITHUB_DEPOLY} ${CODING_DEPOLY})for i in &quot;${!DEPOLYS[@]}&quot;do echo &quot;TRAVIS_BUILD_DIR=${TRAVIS_BUILD_DIR}&quot; cd ${TRAVIS_BUILD_DIR} if [ -d &quot;../repos_${i}&quot; ]; then rm -rf ../repos_${i} fi git clone --depth=1 ${DEPOLYS[${i}]} ../repos_${i} rm -rf ../repos_${i}/* &amp;amp;&amp;amp; cp -a _site/* ../repos_${i}/ cd ../repos_${i}/ git add -A git commit -m &quot;Travis-CI automated deployment #${TRAVIS_BUILD_NUMBER}.&quot; git push ${DEPOLYS[${i}]} master:master echo &quot;Push to ${DEPOLYS[${i}]}&quot;doneBash 脚本执行了笔者用 Python 实现的 Category 和 Tag 页面生成工具，然后执行 Jekyll 构建。要注意的一点是，构建需要声明 Jekyll 环境变量JEKYLL_ENV=production，因为它关系到&amp;lt;head&amp;gt;加载 Google Analytic 埋线的逻辑：{% if jekyll.environment == &#39;production&#39; %} {% include google-analytics.html %}{% endif %}成功后把输出的静态文件部署到 USER.github.io 和 USER.coding.me 两个远程仓库。每次 commit message 用 Travis CI 自动生成的构建号 ${TRAVIS_BUILD_NUMBER} 标识。Travis CI 官网配置Travis CI 官网只需要用 GitHub 账号授权登陆就行了，仓库管理页面开启选定的仓库，Travis CI 就会开始监听仓库。每次往仓库推送代码，都会触发自动构建、部署：点击 build|passing 的徽章，还可以生成指定格式的状态图标链接，如 Markdown 格式：生成地址拷贝到项目 README，可以方便的看到项目构建状态。Travis CI 的 Web 界面上有很多配置小细节，根据个人业务需求作个性化选择。现在，整个接入工作完毕，从今以后，便可尽情地往源码仓库提交更新，Travis CI 会在背后矜矜业业的工作，构建错误会邮件通知，否则，就会自动部署最新的内容到 Pages 服务。一切悄无声息的进行，岂不美哉。CI 测试通常在编写 CI 自动化脚本时，免不了经历开发阶段的测试。本地没法模拟 Travis CI 线上虚拟服务的环境，只能把测试阶段的脚本提交到 Travis CI，这会产生过多无意义的 build 记录。Travis CI 只支持清空 build 内部的输出日志，却不能完全删除某个 build 记录，所以这显然是不太稳妥的选择。其实可以用一个小技巧避开这种烦恼，首先在 GitHub 上创建工作仓库的一个副本，例如正在开发的项目为 AwesomeProj，那么可以先创建一个副本仓库，命名为 AwesomProj-CI，然后在这个项目上面集成 Travis CI 服务，集成期间可以尽意地推送到 Travis CI 上测试效果，直至脚本和配置成熟了，再拷贝到原始仓库 AwesomeProj，然后删除临时仓库 AwesomProj-CI 即可，Travis CI 服务器就会自动清掉临时项目的所有记录，而 AwesomeProj 项目在 Travis CI 上没有任何测试性的 build 记录，纯洁美观。片尾花絮修改 Git 远程地址对 Travis 加密的影响假设你在 Git 仓库调用过 Travis 本地加密命令 travis encrypt，那么仓库的 .git/config 就会被写入变量 travis.slug，内容是:username/repositoryusername 为用户名，repository 为仓库名。本地修改 Git 远程地址后，上述 travis.slug 的值是不会改变的。若此时再调用 Travis CLI 加密，Travis CI 服务端就不能正确解密。正确的做法应该是：将 username 和 repository 更改成于新地址一致的内容，再执行 travis encrypt:$ git config travis.slug new-username/new-repositoryTravis 的两个站点请注意 Travis CI 有两个官网： https://travis-ci.org https://travis-ci.comorg 域名是对开源项目提供服务的，com 域名是对私有项目提供服务。笔者之前用同一个 GitHub 账号在两个域名都关联了一次。结果悲催了：每次 git push，就会收到 Travis 两个不同 build number 的邮件通知，org 域名的 “passing”，com 域名的 “failling”，因为没发现域名的不同，这个乌龙问题困扰了笔者两三天，后来在 GitHub 取消对 com 域名授权就解决了。参考链接 Jekyll Docs: Travis CI Travis CI Docs Using Travis CI to build a Jekyll site" }, { "title": "Jekyll 的 SEO 优化", "url": "/posts/the-seo-to-jekyll/", "categories": "Tech, Website", "tags": "seo, robots, jekyll", "date": "2018-10-30 12:16:00 +0800", "snippet": "近来对博客主题、架构改进的热情明显高于写文章，略有本末倒置的意味。愧疚感驱使笔者写下最近为站点做的一些 SEO 优化： 爬虫保护 目录访问保护 permalink爬虫保护万维网上的站点，都会被搜索引擎爬虫抓取内容，以之作为搜索结果列表。搜索引擎会依据站点根目录的 robots.txt 所定义的规则，去抓取当前站点的内容。对于运行在 GitHub Pages 的站点，默认会生成一个文件 robots.txt，内容为：Sitemap: https://DOMAIN/sitemap.xml其中 DOMAIN 表示站点域名，指令定义 Sitemap 文件位置。为了指示爬虫 Bot 不去抓取某些图片、文件等静态资源，可以在 robots.txt 中新增自定义的指令。首先在站点根目录新建文件robots.txt 去覆盖自动生成的默认版本。接着添加爬虫指令：指定 robots 范围，通配符 * 表示对所有 robot 适用：User-agent: *指定禁止抓取的路径，请注意目录必须以 / 结尾：Disallow: /target_dir/ # 禁止目录Disallow: /targer_file.extension # 禁止文件看了相关资料介绍，因为 robots.txt 文件是可以被直接访问的，所以在文件中直接列出具体目录，会暴露网站的目录结构，所以根据建议，在根目录建一个专门对 Bots 隐藏的目录 /norobots/，将所有需要隐藏的零碎文件、目录等挪到里面即可。笔者的指令为：Disallow: /assets/ # /assets/ 是常规资源目录，不怕暴露路径Disallow: /norobots/ # 零碎敏感文件、目录等放置在此 注：此时浏览器直接访问站点 ${HOST_DOMAIN}/norobots/还是可以看到文件列表的，达不到隐藏站点目录结构的目的，下文再作保护介绍。最后要增加对 sitemap 的指令:Sitemap: https://blog.cotes.info/sitemap.xml如果更换了域名，就要手动的更改 Sitemap 地址。此时可以使用 Jekyll 的全局配置变量取代硬编码：robots.txt 文件顶部添加 Jekyll 的 Assets 声明(YAML)：---layout: null---然后 Sitemap 指令修改为：Sitemap: {{ site.url }}/sitemap.xml这样域名就会随着 _config.yml 自动更改了。完整的 robots.txt 内容如下：---layout: nullpermalink: robots.txt---User-agent: *Disallow: /assts/Disallow: /norobots/Sitemap: {{ site.url }}/sitemap.xmlJekyll 目录保护出于安全考虑，站点的某些目录结构，譬如上文提到的 /norobots/，不希望被外部访问，所以需要使用重定向来保护目录。部署在 GitHub 上的 Jekyll 站点，Apache Web Server 的 .htaccess 重定向规则会被无视（详见官方介绍)，所以可以使用 GitHub 推荐的 Jekyll 重定向插件 Jekyll Redirect From。GitHub Pages 默认支持该插件，在项目的 Gemfile 里添加引用即可：gem &quot;jekyll-redirect-from&quot;接着，在站点 404 页面的 YAML 头部添加跳转规则：---redirect_from: - /norobots/---具体的目录可以更具自己站点的实际情况定义，按照上述定义，访问 ${HOST_DOMAIN}/norobots/会直接返回 404 页面，从而保护了敏感目录。Permalink 优化Permalink 是 &quot;Permanent link&quot; 的缩写，意为「永久链接」，即浏览器访问站点资源的完整路径地址。对于 SEO 而言，越短越精简的 permalink 越容易被发现及提高排名。Jekyll 理所当然的有对 permalink 提供模版支持。如果 page 的 permalink 没有定义，则默认值为:permalink: /:categories/:year/:month/:day/:title:output_ext详细的 permalink 可选值请参考 Jekyll 的 Permalink 介绍。如本文，默认 permalink 是: https://blog.cotes.info/developer/2018/10/30/the-seo-to-jekyll.html，很长的一串，对吧。SEO 建议 permalink 长度不超过 90 个字符，目录层次不超过 3 层，所以为了精简 permalink，计划去掉 categories，year，month，day，output_ext。为了全局生效，在站点根目录 _config.yml 文件添加对 permalink 的赋值：permalink: /:title/上述变量表示：文件站内链接格式为 /{{ page.title }}/，隐藏了静态文件的后缀，如 .html。在末尾加 / 是为了区分带扩展名的访问：若 permalink 定义为 /:title，访问 /:title:output_ext 是被允许的。精简后，本文链接地址为：https://blog.cotes.info/the-seo-to-jekyll/，有效提高了 SEO 表现。 过程中曾担心只剩标题会不会引起文件名重叠，后来细想一下，post 的标题都是短句，机率很小，万一真有重名，可以末端添加数字区分。值得一提的是，博客内部原有的带 .html 后缀的跳转 URL 也要相应修改，需要付出一定的时间去细心校验。结语本文只是对建站动态的阶段性小结，SEO 的玩法远不止这些，有兴趣可以自行查找更多资料。参考链接 SEO Learning Center: Robots.txt Jekyll Docs: Permalinks" }, { "title": "罗马复兴之游牧术", "url": "/posts/the-nomadic-tactics-of-aoe/", "categories": "Living, Game", "tags": "age of empires", "date": "2018-10-04 22:32:00 +0800", "snippet": "罗马复兴（帝国时代）的开图局，有一种战术非常灵活和致命，它就是游牧。释义何为游牧？其实就是和常规阵地战相反的战略思维，农民、建筑、兵马都能随着实时的战局需要随时移动。它对玩家的控兵能力有着极高的要求，宏观资源发展的动态思维也要具备，门槛高。特点及优势在进攻端，游牧能够做到敌明我暗，避实击虚，宛如匿藏在黑暗中的刺客，尖刀出其不意的刺入对手的咽喉。发展方面，游牧不需要考虑地形是否适合防御，因为专职发展的农民都游走四方，对方难以集中打击。此外还可以忽略初始资源的远近影响，由于没有阵地的概念，农民可以主动移到远处的果堆或者鹿、象等肉源，即便因为远出采肉而滞后升铜的时间线，也是可以接受的，因为通常兵营靠近敌方阵地建造，可以缩减箭马抵达战区的时间，弥补可能发生的升级滞后时间，首次出兵时间并不会减慢太多。具体战术 依照主流玩法，本战术执行者为殷商民族。在石器时代，发展和常规阵地战无太大差异。升级下一代文明之前，8 个农民建两个 BS 伐木，14 个农民采果，2 个农民待命远征，总人口为 24 时升级。文明升级间隙，2 个远征的农民必须马不停蹄的往敌营跑，如果是 3 v 3 战局，选择对方比较靠近的两家中间点的森林作为目的地。若是 2 v 2 或者 1 v 1，则随意选一家即可。工具时代升级完毕，BH 多出 1 个农，与此同时，主营选 2 农建 BM 市场、远征的 2 农建 BA 射箭场，建毕再立即升级文明（此时人口总数为 25 ）。工具升铜期间，生产结构改为 10 农采肉，15 农伐木。要注意远征的 2 农要持续扩建 BA，直至建完 5 个 BA，就临近建 BS 伐木。升铜完毕，BM 马上升轮子，主营增加农民数量，总农民数量逐渐增至 30 以上，采果的农民分两队，每队 6～7 人，编 3、4 号分别管理。分开采果，保持双备份状态，可以保障后面 5 马不断。伐木的农民也可以分两队编号，分别编 5、6 号，方便敌兵攻击时跑路躲藏。基础的发展、建筑布局至此基本完毕，剩下的就是疯狂出兵大杀四方了。出兵可以立即抵达到敌营腹地，往往会造成对方的惊慌，注意点都是在第一批 5 个进攻的箭马上。人一慌就会出现破绽，第二队兵循着对方守兵（追我的第一波次攻击箭兵）尾后进入主营农田或者伐木点的农民堆，无情屠农。开战初期的首要准则是，不能直接和对方怼兵，因为阵地战的发展速度总是比游牧要快的，出兵数量会逐渐拉开，单纯怼兵基本是怼不过的。正确的做法是，诱敌主力移开其农民，然后用奇兵杀农，或者歼灭敌方零星的守兵。第二个准则是农民跑路。每次战号响起，必须要用余光看一眼右下角的总地图，看看自己的农民有没有被攻击，如果地图看到警告的闪烁斑点，立马转移农民，挪个安全的地方再生产，进攻的兵可以先拉开到空阔的地方暂时休战。3 v 3 的混战，在队友配合下，通常在 00:22 至 00:27 附近，就可以驱逐或降服者第一家。此后要立马和队友攻陷对方联盟的中路，如果我方另一个边路和敌方的边路单挑失败也不要紧，只要打下对方两家，就能形成 2 : 1 的战略优势。游牧是战损比极高的战术，最后的杀敌数与损失数比例达到 2 : 1 或者更高，即可判定战术执行是成功的。农民可以损失，但是最后存活的应该不少于 15 农。弱点及应对游牧也有几个固定的弱点。第一，运气不好的话，农民容易被团灭暗杀，游牧的农民通常只分为四队，一旦被发现及围住，跑也跑不掉。应对方法：首先必须要时刻盯着地图，关注农民安危。其次农民发展资源选址建议选择到既开阔又隐蔽的地方。第二，怕开局初期兵营被摧毁。如果敌方很早发现 BA 的位置，就会出重兵包围拆兵营，相当于进攻手段被点穴了。应对：兵营选址要隐蔽。第三，3 v 3 局中，游牧怕持久战。首先，对方进入铁器时代，自己的铜器射手就难以支架了。其次，如果自己是中路，和 A 队友攻击对方边路时，如果不能快速攻下，对另一个队友 B 的境地则会越危险，因为他可能面临着对方 2 v 1。应对：只能全力断其一指了，攻不下只能说明竞技水平存在差异，惟有十年后再战。极端战局经验3 v 3 对方也玩游牧游牧不是新东西，只是不是主流玩法。所以偶尔也会碰上对方有一家和自己一样，是玩游牧的。这种情况下，自己的农民就成为被追猎的对象，农民可以向兵营附近靠近发展，被攻击时也方便派兵保护。另外，自己进攻的焦点就要从对方阵地型选手移向那个玩游牧的家伙了，游牧对游牧，就像狙击手对狙击手一样，是对总体战局走势最有利的方式。3 v 3 对家工具时代就打农民玩阴招有一次还遇到个奇葩对手，当时 3 v 3 笔者在边路，可能和对家边路靠得近，升工具的时候，采果采到他家附近了，结果对方派 11 个农民就进来主营搞事情，想杀农，其后又聚集攻击 BH，自己不发展了，鱼死网破，打算在工具升铜器的时候干掉 BH，延误笔者升级。得益于游牧，对方很难找到笔者农民，所以在升铜之前，农民都是主动避开，转移维持发展。被攻击的 BH 可以派农民维修，撑到升铜完毕就可以放弃了。对方少了 11 个农发展，最后升级肯定大大落后，等笔者出兵了还维持在工具时代，只能坐等被虐。" }, { "title": "从 Google Analytics 获取 Pageviews", "url": "/posts/fetch-pageviews-from-google-analytics/", "categories": "Tech, Website", "tags": "google analytics, gae, nginx", "date": "2018-08-28 16:07:00 +0800", "snippet": "人的欲望总是不断膨胀的，笔者是凡人，也难逃此劫。近来，它滋生成为对博客功能的一个新需求：获取 GA (Google Analytic) 的 Pageviews。本站开建早期，就嵌入了 GA 的数据收集代码。它的功能仅限搜集跟踪记录并上传，没法同时返回统计信息。于是调研 Google 相关开发手册，得知 GA 中一个称为 Reporting 的组件，内含几个 API 对外提供处理后的数据，其中 Core Reporting API 支持按特定的维度、指标查询记录。所以使用这部分 API 就能得到所需要的 Pageviews 了。根据 Core Reporting API 的教程。通过 JS 获取的 GA 报告，需要在代码提供 Google APIs 项目的一个信任凭证、OAuth client ID，以及 GA 的 Account Explorer 的 viewID。这三个都是站点拥有者登陆控制台才能看到的私人信息，即便可以在设置域名过滤来限定这几个值只能在自己名下的站点使用，但是直接暴露在 JS 中对外可见，似乎不太优雅。因此，从 Web 调用 Core Reporting API 读取 Pageviews 的可行性是直接否定了。不久后，找到了一个对外安全获取 GA 数据的方案：GA Super Proxy。SuperProxy 涵盖了所有 GA Reporting 组件的 API，上述的凭证、ID 之类的敏感信息可以写入 SuperProxy 的配置，由它代为请求数据。将 SuperProxy 部署在 GAE (Google App Engine)上，敏感信息对外不可见，这样就成了一个持续公开指定 GA 数据的广播站了，网站再从 GAE 读取数据并展示即可，美滋滋。SuperProxy 配置与部署第一步是攻克 SuperProxy。项目仓库 README 有介绍安装步骤以及解说 Live，强烈建议动手前看一下作者的 Live 视频，从项目架构原理到实际操作都有详细表述。请注意项目发布距今已有 5 年（2013 年发布），GCP (Google Cloud Platform) 布局已经不可同日而语，项目 README 以 Live 的部分操作内容已经过时，所以更新描述一下当前最新环境的操作。Google APIs 创建项目用 Google 账户登陆 Google APIs Dashboard，Create Project新建一个 Project，如起名cotes-blog-ga，”Location” 项默认为 No organization。新建完毕后，为项目开启 API 和服务。+ ENABLE APIS AND SERVICES进入 API Library，搜索栏中搜关键词 “analytic” 即可找到 Analytics API，点击图标进去 Enable 此 API 服务即可。开启 API 后页面会自动回到 Dashboard，根据 ⚠️ 信息提示点击 Create credentials 为 API 创建 credentials。创建页面作如下操作： Find out what kind of credentials you need Where will you be calling the API from? 下拉选择 Web brower(Javascript) What data will you be accessing? 选择 User data Create an OAuth 2.0 client ID Client ID 自定义命名，笔者为 blog-oauth Restrictions 两项暂时留空，往后将会写入 GAE 的项目地址。 Set up the OAuth 2.0 consent screen Email 保持默认值 产品名称自定义命名，不与其他公司产品重名即可，例笔者为 cotes-blog-ga Download credentials 视个人需要决定下载与否，供 SuperProxy 使用的 Client ID，Client secret 都可以在 Dashboard 直接查看。 完成后即可生成新 OAuth 2.0 client ID: 上述 API Dashboard 的操作就算过程中的填写信息有纰漏也不用担心，API Dashboard 相互之间的各个按钮开关总是可以跳转到所需页面，十分友好。下载配置 SuperProxy在本地满足环境依赖： 安装 Python 27 安装 Cloud SDK for Python 墙内的童鞋可能在本地 Cloud SDK 登陆 Google 账户会受限，可以考虑使用 Cloud SDK 网络代理 解决。接着下载 SuperProxy 项目，SuperProxy 的配置基本按照作者的 README 介绍修改即可。1. 修改 src/config.py OAUTH_CLIENT_ID - 填入上一步创建的 Client ID OAUTH_CLIENT_SECRET - 填入 Client secret OAUTH_REDIRECT_URI - 填入 GAE 派发的免费域名 https://PROJECT_ID.appspot.com，其中 PROJECT_ID 在 Google APIs Dashboard 或者其他任一 GCP 页面中，点击顶栏项目名即可查看。 OAUTH_REDIRECT_URI - 配置内默认在地址尾部添加了 /admin/auth，所以 URI 全貌为：https://PROJECT_ID.appspot.com/admin/auth。此时再返回上一步的 Credentials，点击 OAuth 2.0 client IDs 中的 OAuth ID，在设置页面的 Authorized redirect URIs 填入 SuperProxy 中 OAUTH_REDIRECT_URI 的完整地址，例如，笔者是：https://cotes-blog-ga-214617.appspot.com/admin/auth。2. 修改 src/app.yamlsrc/app.yaml 文件首部两行：application 与 version，在 Cloud SDK 213.0.0 中已经标记为无效字段了，需要将其删除，否则部署时会出现警告而导致中断。- application: your-project-id- version: 1上传 SuperProxy 至 GAE进入 SuperProxy 源码 src/ 目录，使用 Cloud SDK 命令上传：$ gcloud app deploy app.yaml index.yaml --project PROJECT_IDPROJECT_ID 替换成项目 ID，笔者的是：cotes-blog-ga-214617GAE 上创建查询登陆 https://PROJECT_ID.appspot.com/admin，验证账户后创建查询。GA Core Reporting API 查询请求可以在 Query Explorer 创建。因为要查询的是 Pageviews，所以笔者的查询参数如下： start-date - 填写博客发布首日 end-date - 填 today (这是 GA Report 支持的参数，表示永远按当前查询日期为止） metrics - 选择 ga:pageviews dimensions - 选择 ga:pagePath 为了减少返回结果，减轻网络带宽，所以增加自定义过滤规则1： filters - 填写 ga:pagePath!@=;ga:pagePath!@( 其中 ; 表示用 逻辑与 串联两条规则，!@= 表示不含 =，!@( 表示不含 (。 Run Query 之后在页面底部拷贝 API Query URI 生成内容，填至 GAE 上 SuperProxy 的 Encoded URI for the query 即可。GAE 上保存查询后，会生成一个 Public Endpoint（公开的访问地址），用户访问它将返回 JSON 格式的查询结果。最后，在 Public Request Endpoint 点击 Enable Endpoint 使查询生效，Scheduling 中点击 Start Scheduling 开启定时任务。Web 端处理 GA 数据Web 中使用 AJAX 获取 pageviews 数据，动态刷新到页面指定位置。关键代码：$.ajax({ url: &#39;PUBLIC_ENDPOINT&#39;, // Replace with SuperProxy Public endpoint dataType: &#39;jsonp&#39;, // for cross-origin access timeout: 1000 * 10, // 10 secs success: function(data) { displayPageviews(data.rows); // Do what ever you want. }, error: function() { console.log(&#39;Failed to load Pageviews!&#39;); }});展示 Pageviews 的逻辑函数 displayPageviews 可以根据个人的实际需求实现，笔者需要的是每篇 Post 首部展示 Pageviews，所以在页面指定位置添加 HTML 元素 &amp;lt;span id=&quot;pageviews&quot;&amp;gt;&amp;lt;/span&amp;gt;，JS 逻辑实现如下：function displayPageviews(rows) { if (rows === undefined) { return; } var curPath = window.location.pathname; var curFile = curPath.slice(curPath.lastIndexOf(&#39;/&#39;) + 1); // Sometimes posts will be moved. var len = rows.length; var cnt = 0; for (var i = 0; i &amp;lt; len; ++i) { var gaPath = rows[i][0]; var gaFile = gaPath.slice(gaPath.lastIndexOf(&#39;/&#39;) + 1); if (gaPath === curPath || gaFile === curFile) { cnt += parseInt(rows[i][1]); } } $(&#39;#pageviews&#39;).text(cnt);}不出意外的话，现在 GitHub 上部署的博客可以顺利展示 Pageviews 了。扩展：墙内访问 GAE经过上文一通猛如虎的操作，GitHub 托管的站点是解决了 Pageviews 问题。但是如果访问者身处「全球最大的局域网」内呢？那么上述的 Web 端处理手段就要失效了，发出的请求，在光明降临这片土地之前，永远无法得到返回。破此困局，须借道海外 VPS，另外如果还有个私人域名的话就更佳了。下面说一下笔者的解决方案：VPS 运行在海外，且能被国内正常访问。VPS 上通过 Nginx 对 GAE Application 域名作反向代理，墙内用户即可通过 VPS 访问到 GAE 上的数据。笔者的 VPS 公网地址绑定了私人域名 api.cotes.in，并且申请了 SSL 证书。那么，Nginx 的反代 GAE 的关键配置如下： 注：Nginx 监听 SSL 需要事先安装相应的模块。server { listen 443 ssl; ssl on; server_name api.cotes.in; ssl_certificate /etc/letsencrypt/live/api.cotes.in/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/api.cotes.in/privkey.pem; location /ga/ { proxy_redirect off; proxy_set_header Host cotes-blog-ga-214617.appspot.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass https://cotes-blog-ga-214617.appspot.com; rewrite ^/ga/(.*)$ /$1 break; }}这份配置为域名 api.cotes.in 开启了 SSL，把笔者的 GAE Application 域名 https://cotes-blog-ga-214617.appspot.com 代理至墙内可见的地址 https://api.cotes.in/ga/。另外，proxy_set_header Host 很关键，GAE 需要根据它寻找你的 Application。Web 端的 AJAX 也要扩展：$.ajax({ url: &#39;https://cotes-blog-ga-214617.appspot.com/query?id=ahZifmNvdGVzLWJsb2ctZ2EtMjE0NjE3chULEghBcGlRdWVyeRiAgICA3pCBCgw&#39;, dataType: &#39;jsonp&#39;, // for cross-origin access timeout: 1000 * 5, // 5 secs success: function(data) { displayPageviews(data.rows); }, error: function() { // Get GA-reports by proxy $.ajax({ url: &#39;https://api.cotes.in/ga/query?id=ahZifmNvdGVzLWJsb2ctZ2EtMjE0NjE3chULEghBcGlRdWVyeRiAgICA3pCBCgw&#39;, dataType: &#39;jsonp&#39;, timeout: 1000 * 5, success: function(data) { console.log(&#39;Load gae from proxy.&#39;); displayPageviews(data.rows); }, error: function() { console.log(&#39;Failed to get pageviews from proxy.&#39;); } }) }});上述代码（第 13 行）增加对 GAE 代理地址的请求，如此一来，墙内用户可以享受到无差别的数据服务了。参考资料 Analytics Reporting API v4 Google Analytics SuperProxy Pageview from Google Analytics for Your Blog引用 Google Analytics Core Reporting API: Filters &amp;#8617; " }, { "title": "Jekyll 网站性能优化", "url": "/posts/jekyll-site-performance-optimization/", "categories": "Tech, Website", "tags": "jekyll, css, js, html", "date": "2018-08-19 20:22:00 +0800", "snippet": "近来，突然觉博客项目的 CSS 内容越来越多，多次在 HTML 与 CSS 之间增减内容，就会增加残留无效 CSS 的概率，人工筛除颇为费神。经过查找资料，发现 Chrome 的 DevTools 自带的 Coverage 功能可以很好的解决这个问题。好奇心驱使下，自然想着寻找更多玩法，能不能借助 DevTools 提高网站性能呢？答案是肯定的。Lighthouse 是 Chrome 的性能审查扩展程序，位置在 DevTools 的 Audits 选项栏。根据自动化审查结果，可以知道网站性能短板所在，再由报告提供的建议去优化缺陷。Lighthouse 审查Audits 有五项审查内容，分别是 Performance，Progressive Web App，Best parctices，Accessibility，SEO 等，可以根据自己的需要选择。本文针对其中的 Performance（性能）开聊。Chrome 打开目标网页，启动 Audits，十几秒内即可完成审查。网站的性能优化大概有以下几个方向： 跨域资源预处理 JS 异步加载 按业务分拆 JS/CSS 的调用 本地资源压缩 图片懒加载下面将逐项叙述每个优化过程细节。跨域资源预处理对于跨域的静态资源引用，譬如字体、图标资源的引用，在 &amp;lt;link&amp;gt; 标签中使用属性 preconnect 和 dns-prefetch 可以告诉浏览器对跨域资源给予最高优先级，在页面加载一开始就进行处理。 dns-prefetch 告诉浏览器在后台自动获取目标网址的 DNS 信息，这样在页面使用所需资源时就可以减少网络请求的时间。 preconnect 更进一步，除了完成上述工作，还进行 TLS 判断以及 TCP 三次握手，是更为重量级的操作。示例: &amp;lt;link href=&quot;https://cdn.domain.com&quot; rel=&quot;preconnect&quot; crossorigin&amp;gt; 实际应用时，两者会合并使用：&amp;lt;link href=&quot;https://cdn.domain.com&quot; rel=&quot;preconnect&quot; crossorigin&amp;gt;&amp;lt;link href=&quot;https://cdn.domain.com&quot; rel=&quot;dns-prefetch&quot;&amp;gt;两者合用，可以减少后续的跨域延迟。另外，对于不支持 preconnect 的浏览器引擎，还有 dns-prefetch 作后备，dns-prefetch 对浏览器种类和版本的支持比前者要更广1。JS 加载优化默认情况下，DOM 解析和 JS 执行 会同步进行，当浏览器解析到 &amp;lt;script&amp;gt; 标签时，会阻塞 DOM 树的解析，直至 script 内容下载完毕并执行，才会继续 DOM 树的构建 2：gantt dateformat ss axisformat %S ms title Basic situation section HTML build DOM: active, dom, 00, 20s build DOM: active, dom-2, after js-run, 10s section JS fetch script: js-dl, after dom, 10s run script: crit, js-run, after js-dl, 5s浏览器之所以赋予 &amp;lt;script&amp;gt; 标签最高优先级，是因为 JS 代码可以修改 HTML/CSS 的结构及内容，从而对最终渲染结果发生影响，所以必须等候它执行完成才会继续构建 DOM/CSS 树。JS 资源的下载可以和 DOM 树构建异步进行，从而减少或者避免 JS 代码增加页面加载时长。实现方式为： 对 &amp;lt;script&amp;gt; 使用属性 async 或 defer。请注意异步属性只能在外部调用的 JS 资源里使用，即 &amp;lt;script&amp;gt; 标签中必须提供 src 属性。async对页面样式展示非必要的 JS 代码，可以在 &amp;lt;script&amp;gt; 内部添加属性 async 来异步下载 script 内容，减少对 DOM 构建的阻塞。如：&amp;lt;script src=&quot;/assets/js/common.js&quot; async&amp;gt;&amp;lt;/script&amp;gt;即便使用 async 还是会对 DOM 树解析造成阻塞，因为 JS 内容下载完毕后，会被立即执行，若此时 DOM 解析还没完成，就会被阻塞3:gantt dateformat ss axisformat %S ms title With async section HTML build DOM: active, dom, 00, 20s build DOM: active, dom2, after js-run, 10s section JS fetch script: js-dl, 10, 10s run script: crit, js-run, after js-dl, 5s另外，还有个特点，如果同时声明几个 async 资源，那么 JS 资源被执行的次序是随机的，不受控制。defer如果要保障 JS 放在 DOM 完成解析后执行，请使用 defer 属性:gantt dateformat ss axisformat %S ms title With defer section HTML build DOM: active, dom, 00, 30s section JS fetch script: js-dl, 10, 10s run script: crit, js-run, after dom, 5s另外，和 async 不同的地方是，defer 的资源会依照声明顺序来执行。分场景调用 JS/CSS在 Jekyll 中，{% include %} 的应用可以增加代码的简洁性，也可能造成页面的 JS/CSS 冗余。一般 Jekyll 项目的习惯是，项目所有的 JS/CSS 都在 _includes/head.html 中引入，然后通过 {% include head.html %} 导入每个下层 layout。很多时候，部分 JS/CSS 并不是每个页面都必须的。例如，本站的 post 布局需要 bootstrap-toc.js，此外的 page 布局，home 布局都不需要 toc 相关的 JS/CSS。这时应该把 bootstrap-toc 相关的 JS/CSS 单独放置到 post 布局上引用，从而增加了其他布局的加载及渲染速度。本地资源压缩体积CSS 压缩使用 Jekyll 提供的 SASS Pipeline 压缩，每次编译的时候会自动压缩引入的 SCSS 文件，十分便捷。使用方法是，在项目 _config.yml 文件添加 SASS 配置：sass: sass_dir: /assets/css # Override jekyll default path &#39;/_sass&#39; style: compressed其中sass_dir为项目 CSS 目录。将自己编写的 CSS 3 文件后缀修改为 .scss，在 CSS 文件目录 /assets/css下新建一个文件，命名为 styles.scss，添加导入所需的 SCSS。例如，导入 styles.scss同目录下的 main.scss、syntax.scss 两个文件，则 styles.scss 添加内容：------@import &quot;main&quot;;@import &quot;syntax&quot;;项目 &amp;lt;head&amp;gt; 引用作相应修改，去掉原先对每个独立 CSS 文件的 &amp;lt;link rel=&quot;stylesheet&quot;&amp;gt;引用，改为对 styles.css的引用:&amp;lt;link rel=&quot;stylesheet&quot; href=&quot;/assets/css/styles.css&quot;&amp;gt; 引用文件后缀使用了 .css，这是因为 .scss 编译后后缀会被自动改为 .cssJS 压缩项目中自己编写的 JS 以及第三方的 JS 文件（未压缩），可使用 YUI Compressor 压缩，压缩结果命名可以在 .js 后缀前添加 min 标识。如原文件 tools.js 压缩后命名为 tools.min.js。$ java -jar yuicompressor.jar tools.js -o tools.min.js接着使用 Jekyll 的 Assest 特征合并引用所需的 JS，在 JS 目录下新建文件 common.js，使用 {% include %} 引入其他 JS，如本站内容为：------{% include_relative dist/back-to-top.min.js %}{% include_relative dist/category-collapse.min.js %}{% include_relative dist/search-display.min.js %}{% include_relative dist/sidebar-toggle.min.js %}项目 HTML 的 head 中使用合并文件替代分开的几个文件引用：&amp;lt;script src=&quot;/assets/js/common.js&quot; async&amp;gt;&amp;lt;/script&amp;gt;HTML 压缩对于 Jekyll，有一个 Liquid 实现的开源方案提供解决：Jekyll HTML Compressor。安装很简单，首先到 Release 下载最新版的 compress.html，拷贝到项目的 _layouts 目录下。然后修改最顶级的默认样式 _layouts/default.html，在它的头部添加 YAML:---layout: compress---然后，在 _config.yml 添加配置：compress_html: clippings: all comments: [&quot;&amp;lt;!-- &quot;, &quot; --&amp;gt;&quot;] endings: [html, head, body, li, dt, dd, rt, rp, optgroup, option, colgroup, caption, thead, tbody, tfoot, tr, td, th] profile: false blanklines: false ignore: envs: []具体每个参数的含义可以参考项目 README 介绍，经过几步即完成了插件的安装。该注意的是，如果 post 使用了 Jekyll 的 linenos，则需要额外解决内嵌 &amp;lt;pre&amp;gt; 压缩错乱的 BUG。具体表现为, 原始状态使用 {% highlight LANGUAGE linenos %} 时，生成的代码格式为：&amp;lt;figure class=&quot;highlight&quot;&amp;gt; &amp;lt;pre&amp;gt; &amp;lt;code class=&quot;...&quot; data-lang=&quot;...&quot;&amp;gt; Code snippet &amp;lt;/code&amp;gt; &amp;lt;/pre&amp;gt;&amp;lt;/figure&amp;gt;当压缩HTML时，会把最外层的 &amp;lt;pre&amp;gt; 及 &amp;lt;/pre&amp;gt; 删除，但是不完整，残留 /&amp;gt;：&amp;lt;figure class=&quot;highlight&quot;&amp;gt; /&amp;gt; &amp;lt;code class=&quot;...&quot; data-lang=&quot;...&quot;&amp;gt; Code snippet &amp;lt;/code&amp;gt;&amp;lt;/figure&amp;gt;虽然这会造成样式大错乱，但是项目维护者不打算修改这个 bug，认为这样会增加扫描层数，大大增加项目 build 的时间。上述 issue#71 中，已经有用户提供了解决方法：在 _includes/ 中新建文件 fixlinenos.html，添加内容：{% if _code contains &#39;&amp;lt;pre class=&quot;lineno&quot;&amp;gt;&#39; %} {% assign _code = _code | replace: &quot;&amp;lt;pre&amp;gt;&amp;lt;code&quot;, &quot;&amp;lt;code&quot; %} {% assign _code = _code | replace: &quot;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&quot;, &quot;&amp;lt;/code&amp;gt;&quot; %}{% endif %}在每篇 post 源码中，调用 {% highlight LANGUAGE linenos %} 的地方作出修改。原始代码：{% highlight AnyLanguage linenos %} Some code{% endhighlight %}应修改为：{% capture _code %}{% highlight AnyLanguage linenos %} Some code{% endhighlight %}{% endcapture %}{% include fixlinenos.html %}{{ _code }}这样压缩就不会出现问题了，可是要注意的是，&amp;lt;pre&amp;gt; 被 fixlinenos.html 清除后，代码段的 overflow: auto 也会消失，需要为 figure.highlight 添加样式 overflow: auto 对超出父容器宽度的代码作水平滑动。此外，Jekyll HTML Compressor 这个插件还有个局限：对于内嵌在 HTML 页面的 JavaScript 代码，注释若使用 // 会导致压缩错误，需要用 /* ... */ 替代。JSON 压缩这个是个意外发现，和上一步 HTML 压缩 一样，文件头部加 YAML 声明调用压缩的 layout 即可：---layout: compress---服务器 GZIP 压缩传输过程可以开启 Web 服务器的GZIP选项，如果博客是部署在 GitHub Pages 或 Coding Pages ，则默认开启了 GZIP 压缩传输。若是自己个人部署的 Web 服务器，如 Nginx，Apache 等，则需要跟进此点优化。懒加载图片图片是重要的内容资源，但是却不能忽略图片体积对网络带宽带来的负面影响。解决的策略就是对无需立即展示的图片，进行懒加载，也就是当网页滑动到图片所在位置时才进行加载。这个过程可以通过第三方库来完成，如 Lozad.js，轻量级，支持自定义加载过程细节。结语上述只是针对本站的优化，并没有覆盖常规网站的所有优化点，更加全面细致的性能建议，可参考 Google 开发者文档。参考资料 Building the DOM faster: speculative parsing, async, defer and preload Resource Hints - What is Preload, Prefetch, and Preconnect? Resource Prioritization – Getting the Browser to Help You async and defer引用 MDN: dns-prefetch &amp;#8617; Adding Interactivity with JavaScript &amp;#8617; &amp;lt;script&amp;gt;: The Script element &amp;#8617; " }, { "title": "KcpTun 加速 Shadowsocks", "url": "/posts/speed-up-shadowsocks-by-kcptunp/", "categories": "Tech, Shadowsocks", "tags": "kcptun, kcp, shadowsocks, ec2, aws", "date": "2018-08-15 14:18:00 +0800", "snippet": "KCP 是一个快速可靠的 ARQ 协议，通过将 TCP 流量分拆到 UDP 传输，以增加流量的代价去获得低延时，从而大幅提高科学上网的流畅度。KCPTun 是 GO 实现 KCP 协议的工具，由服务端和客户端两部分组成，借助它作远程端口转发可以大幅提高 Shadowsocks（下简称 SS）的速度。总体概述笔者手上有一个 AWS 上运行的 EC2 实例，系统为 RHEL 7.4，上面跑着一个 ss-server 端的 daemon 进程。为了把 SS 流量通过 KcpTun 隧道转发，需要在 EC2 上安装 KcpTun-Server，客户端目标机安装 KcpTun-Client。Shadowsocks 服务端ss-server 安装运行在 EC2 上，配置如下：{ &quot;server&quot;: &quot;0.0.0.0&quot;, &quot;server_port&quot;: 6789, &quot;password&quot;: &quot;your_ss_passwd&quot;, &quot;timeout&quot;: 300, &quot;method&quot;: &quot;aes-256-cfb&quot;}KcpTun 服务端在 KcpTun Release 列表选择系统对应的版本，本例的 EC2 是 64 位 RHEL，故选择最新的 linux-amd64 版本：在 EC2 下载 KcpTun 二进制程序包:$ wget https://github.com/xtaci/kcptun/releases/download/v20180810/kcptun-linux-amd64-20180810.tar.gz解压:$ tar zxvf kcptun-linux-amd64-20180810.tar.gz -C KCPTUN_DIRKCPTUN_DIR替换为放置 KcpTun 的自定义目录。每个发行包里面都含一个 Server 和一个 Client，在 EC2 上只需使用其中的文件 server_linux_amd64 即可。接着，在 KcpTun 目录内新建一个 JSON 配置文件，可取名为 kcptun-server-config.json，添加如下内容：{ &quot;target&quot;: &quot;127.0.0.1:6789&quot;, &quot;listen&quot;: &quot;:7890&quot;, &quot;mode&quot;: &quot;fast2&quot;, &quot;key&quot;: &quot;your_kcp_passwd&quot;, &quot;crypt&quot;: &quot;aes-128&quot;}其中： target - 指向本机 ss-server 的服务 {IP}:{Port} listen - KcpTun 监听端口 mode - KcpTun 模式，可选有 fast3，fast2，fast， normal （默认：fast） key - KcpTun-Server 和 KcpTun-Client 之间的密码 crypt - 加密方式，不填默认 aes更加具体的参数用法及含义可以执行以下命令获得：$ ./server_linux_amd64 -h运行 KcpTun 服务端前，需要确保两点： target 指向的 ss-server 正在运行。 EC2 的 VPC 开放如下规则： Inbound: Type Protocol Port Range Source Custom UDP Rule UDP 7890 0.0.0.0/0 Custom TCP Rule TCP 7890 0.0.0.0/0 Outbound: Type Protocol Port Range Source All TCP TCP 0 - 65535 0.0.0.0/0 All UDP UDP 0 - 65535 0.0.0.0/0 接下来后台运行 KcpTun-Server:$ nohup ./server_linux_amd64 -c /path/to/kcptun-server-config.json &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;KcpTun 客户端相应的，客户端机器也需要运行一个 KcpTun-Client 和一个 SS-Client。选择 1. Shadowsocks-X-NG如果是在Mac机器上，则比较简单：ShadowsocksX-NG-1.7.1 已经在 SS-Client 的基础上集成了 KcpTun-Client，因此只需安装配置一个客户端软件即可。Shadowsocks-X-NG 配置如下： Preferences..选择 Kcptun 项： Local Kcptun Listen Address 填 127.0.0.1 Local Kcptun Listen Port 填写客户端机器空闲端口，本例为 7086 这两项意思为 Kcptun-Client 运行在本地 127.0.0.1:7086。 进入Servers→Server Preferences..添加配置，勾选 Enable over kcptun，如下图： 右侧面板以横线为界，上半部分的 Address 为 EC2 的公网 IP；Encryption 、 Password 与 EC2 上的 SS-Server 配置一致。 下半部分的 Kcptun Port , Mode, Encryption 与 EC2 上的 KcpTun-Server 配置一致。 其中 Kcptun Port 即为 Kcptun-Server 的 listen 值，Password 为 KcpTun-Serve 的 Key。 选择 2. 官方客户端如果客户端机器平台不是 Mac，那么可以直接使用 KcpTun 的官方Client，为了方便可以建立配置文件，命名为 kcptun-cli-config.json：{ &quot;remoteaddr&quot; : &quot;EC2_IP:7890&quot;, &quot;localaddr&quot; : &quot;127.0.0.1:7086&quot;, &quot;mode&quot; : &quot;fast2&quot;, &quot;key&quot; : &quot;your_kcp_passwd&quot;, &quot;crypt&quot; : &quot;aes-128&quot;,}daemon 运行 KcpTun-Client:$ nohup ./client_darwin_amd64 -c /path/to/kcptun-cli-config.json &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;Shaowsocks GUI 客户端使用配置：{ &quot;method&quot; : &quot;aes-256-cfb&quot;, &quot;server&quot; : &quot;127.0.0.1&quot;, &quot;password&quot; : &quot;your_ss_passwd&quot;, &quot;local_address&quot; : &quot;127.0.0.1&quot;, &quot;server_port&quot; : 7086, &quot;timeout&quot; : 60, &quot;local_port&quot; : 1080}不出意外，此刻你已体验到了 KCP 的快感。笔者实测，YouTube 视频码率用 Auto 模式，使用纯 SS，加载视频为 480P。当使用 KcpTun 后，加载分辨率跳到了 1080P！后话Kcptun-Client 目前没有 iOS 平台的 APP，暂时只能用一台墙内 VPS 运行 Kcptun-Client 作中转，让 iOS 上用普通的 SS-Client 链接使用。另外，KCP 是个双刃剑，流量敏感的用户需要在 KcpTun-Server 上针对性的修改调整更多的参数，达到最好的性价比。" }, { "title": "GitHub &amp; Coding 双线开启 HTTPS", "url": "/posts/enable-https-on-githubpages-and-codingpages/", "categories": "Tech, Website", "tags": "nginx, dnspod, https, ssl, tls", "date": "2018-07-01 21:34:00 +0800", "snippet": "早前借助 DNSPod，GitHub Pages 和 Coding Pages，实现了 Jekyll 博客的国内外双线部署。但没有用上 SSL/TLS，浏览器地址栏上缺失的小锁，一直是心中的遗憾。用上 HTTPS 的好处不用多言，谷歌搜索结果优先排列，国内移动上网不会给无耻运营商插入广告。所以，本文将在此前基础上，叙述如何双线启用 HTTPS。 调研双线 SSL 的时候，GitHub Pages 还不允许自定义域名开启 HTTPS，所以本文使用 VPS 反向代理的方式解决此问题。 2018 年 5 月 1 日起，GitHub 官方已经开启自定义域名 HTTPS 支持(见官方公告)。前提 一个域名 一台墙外VPS原理flowchart LR subgraph VPS ssl(Let&#39;s Encrypt) ngx(Nginx) end u0([Oversea User]) -- oversea --&amp;gt; dnspod[DNSPod] u1([Local User]) -. inland .-&amp;gt; dnspod dnspod -- oversea --&amp;gt; ssl ngx -- reverse proxy --&amp;gt; gh-pages[GitHub Pages] ssl o--o ngx dnspod -. inland ...-&amp;gt; cd-pages[&quot;Coding Pages\\n(with Certification)&quot;]在本案例，来访请求由 DNSPod 作动态分析： 海外访问请求经过 VPS 上运行的 Nginx 反代至 GitHub Pages，VPS 上须申领一份 Let&#39;s Encrypt 的 SSL/TLS 证书。 国内的访问则直接连接 Coding Pages，证书由 Coding.net 代由申领，皆为 Let&#39;s Encrypt 提供。笔者拥有的二级域名是 cotes.in，计划把三级域名 blog.cotes.in 映射至 GitHub Pages 及 Coding Pages 两个站点的博客。接下来，是激动人心的配置过程了。海外线路DNSPod配置GitHub Pages 绑定自定义域名不允许使用 HTTPS, 所以需要添加一个 A 记录指向 VPS 的 IPv4 地址。进入 DNSPod 控制台，对域名 blog.cotes.in 添加唯一的国外线路记录（此前双线 HTTP 时添加的国外 CNAME 记录删掉）：VPS获取证书本案例使用 certbot 获取 Let&#39;s Encrypt 提供的免费证书，RHEL 7 安装 certbot 具体步骤见安装 certbot，在此不再复述。申请证书要保证目标服务器的 80 端口可访问，接收 HTTPS 访问需保证 443 端口开放。所以须在 VPS 进站出站规则允许开放 80 及 443 端口。完成上述准备后，SSH 登录至运行 RHEL 的 VPS，为博客域名 blog.cotes.in 申请证书：$ sudo certbot certonly --standalone -d blog.cotes.in --standalone 表示 certbot 会自己运行一个 web server 来进行验证，为避免冲突须关闭 Nginx 及 Apache 等服务。成功的输出信息会包含证书存放目录，若忘记可用命令查看：$ sudo certbot certificatesSaving debug log to /var/log/letsencrypt/letsencrypt.log-------------------------------------------------------------------------------Found the following certs: Certificate Name: blog.cotes.in Domains: blog.cotes.in Expiry Date: 2018-09-29 07:35:36+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/blog.cotes.in/fullchain.pem Private Key Path: /etc/letsencrypt/live/blog.cotes.in/privkey.pem-------------------------------------------------------------------------------输出信息末端的 Certificate Path 及 Private Key Path 就是证书存放路径。Nginx SSL反向代理Nginx 确保开启了 SSL 模块 ngx_http_ssl_module，在配置文件的 http 模块中添加两个 server：server { listen 443 ssl; ssl on; server_name blog.cotes.in; ssl_certificate /etc/letsencrypt/live/blog.cotes.in/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/blog.cotes.in/privkey.pem; location / { proxy_pass https://cotes2020.github.io; proxy_redirect off; proxy_set_header Host blog.cotes.in; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }}server { listen 80; server_name blog.cotes.in; rewrite ^(.*) https://$server_name$1 permanent; location / { proxy_pass https://blog.cotes.in; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $host; } # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }}监听 443 端口的 server 模块里，把 https://blog.cotes.in 跳转至 GitHub Pages 的派发地址：https://cotes2020.github.io。监听 80 端口的 server 模块把 HTTP 请求跳转到 HTTPS。检测配置语法：# nginx -t重载配置：# nginx -s reload证书自动更新见站内 certbot 自动更新描述。国内线路由于采用国内外双线部署，DNSPod 需要暂时关闭国外路线：这样在 Let&#39;s Encrypt 检查域名是否可用时，能够正确连接到 CodingPages 的地址。接着 Coding Pages 项目控制台开启 HTTPS：成功后 Coding Pages 控制台会出现证书信息：最后，回到 DNSPod 恢复域名的国外线路记录。资源格式采用 HTTPS 的页面，需要将已有的图片、视频资源链接都采用 HTTPS。否则，会导致页面加密失败，变回 HTTP 传输。参考 在 Amazon Linux 2 上将 Let&#39;s Encrypt 与 Certbot 结合使用 反向代理 GitHub Pages 启用 HTTPS" }, { "title": "Nginx 反向代理 Apache SSL", "url": "/posts/nginx-reverse-proxy-apache-ssl/", "categories": "Tech, Website", "tags": "nginx, apache, rhel", "date": "2018-06-29 17:46:00 +0800", "snippet": "笔者的 VPS 上运行了一个 Apache 的 PHP 服务，采用 HTTP 协议。现在打算为这个服务升级为 HTTPS，所以借用了 Nginx 反向代理实现目标。环境 RHEL 7.4 Apache 2.4 Nginx 1.10.1前提 安装 Apache Web Server，若没安装则参考安装指南。 安装 Nginx（开启 SSL 模块）。 注：如果之前为 Apache Web Server 配置过 SSL，则需要通过移除 mod_ssl 的方式关闭 Apache 的 SSL 功能： $ sudo yum -y remove mod_ssl Apache 更改默认端口Nginx 替代 Apache 作为最外层，所以需要腾出 Apache 的 80 端口，改为任意的空闲端口，仅供内网使用，如改为 7890 。取得 root 权限，修改配置文件 /etc/httpd/conf/httpd.conf，把 Listen 80 改为 Listen 7890。SELinux 规则开放新端口 7890：$ sudo semanage port -a -t http_port_t -p tcp 7890确认端口 7890 已添加：$ sudo semanage port -l | grep -w http_port_thttp_port_t tcp 7890, 80, 81, 443, 488, 8008, 8009, 8443, 9000重启 Apache:$ sudo systemctl restart httpd检查新端口是否生效：$ sudo netstat -ntlp |grep httpdtcp6 0 0 :::7890 :::* LISTEN 18000/httpd安装 certbot对于 RHEL 7，需要下载存 EPEL 7 储包，才可提供 certbot 的依赖项：$ sudo wget -r --no-parent -A &#39;epel-release-*.rpm&#39; http://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/安装 EPEL 7:$ sudo rpm -Uvh dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-*.rpm启用 EPEL:$ sudo yum-config-manager --enable epel*确认开启 EPEL:$ sudo yum repolist all...repo id repo name statusepel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 enabled: 12607epel-debuginfo/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 - Debug enabled: 2791epel-source/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 - Source enabled: 0epel-testing/x86_64 Extra Packages for Enterprise Linux 7 - Testing - x86_64 enabled: 702epel-testing-debuginfo/x86_64 Extra Packages for Enterprise Linux 7 - Testing - x86_64 - Debug enabled: 110epel-testing-source/x86_64 Extra Packages for Enterprise Linux 7 - Testing - x86_64 - Source enabled: 0...安装依赖及开启 channel：$ sudo yum -y install yum-utils$ sudo yum-config-manager --enable rhui-REGION-rhel-server-extras rhui-REGION-rhel-server-optional安装 certbot：$ sudo yum -y install python2-certbot-nginx获取 certbot 证书确保 VPS 对外开放端口 80 及 443，为指定域名获取证书，如本例域名为 api.cotes.in：$ sudo certbot certonly --standalone -d api.cotes.in获取成功的输出信息：Saving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator standalone, Installer NoneStarting new HTTPS connection (1): acme-v01.api.letsencrypt.orgCert is due for renewal, auto-renewing...Renewing an existing certificatePerforming the following challenges:tls-sni-01 challenge for api.cotes.inWaiting for verification...Cleaning up challengesIMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/api.cotes.in/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/api.cotes.in/privkey.pem Your cert will expire on 2018-09-27. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run &quot;certbot renew&quot; - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let&#39;s Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le其中包含了证书文件的目录: /etc/letsencrypt/live/api.cotes.in/fullchain.pem /etc/letsencrypt/live/api.cotes.in/privkey.pem另外还有证书的到期时间 2018-09-27。修改 Nginx 配置在配置文件 nginx.conf 的 http 模块里添加两个 server 模块：http { ... # Https for Apache server { listen 443 ssl; ssl on; server_name api.cotes.in; ssl_certificate /etc/letsencrypt/live/api.cotes.in/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/api.cotes.in/privkey.pem; location / { proxy_pass http://127.0.0.1:7890; proxy_redirect off; proxy_set_header Host api.cotes.in; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location ~ /\\.ht { deny all; } } ## Apache http port 80 server { listen 80; server_name api.cotes.in; rewrite ^(.*) https://$server_name$1 permanent; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } # other settings ...}修改配置后执行语法检测：$ nginx -t通过检测后重新加载配置文件:$ nginx -s reloadcertbot 自动更新更新前必须先确保申请机的 443 端口保持空闲状态，因为 Let&#39;s Encrypt 服务器会访问申请机器的 443 端口。上述运行着的 Nginx SSL/TLS 反代服务会占用 443 端口，所以必须暂时关闭 Nginx，再使用 certbot 命令执行更新，完毕后重新开启 Nginx 服务。将上述原理写成 Shell 脚本，命名为 certbot-updater.sh。添加内容:#!/bin/bashif [[ $(certbot certificates |grep &quot;INVALID: EXPIRED&quot;) ]]; then # Check if the certificaties has expired. nginx -s stop &amp;amp;&amp;amp; \\ certbot renew --no-self-upgrade &amp;amp;&amp;amp; \\ # Update certificaties nginxfiif 中判断证书是否过期的逻辑，是通过 certbot 证书状态输出信息做判断，更加严谨点可以根据具体的过期日期转换为时间，和当前查询时间对比作为判断依据。现在上述脚本文件放置到心仪的目录下，由 crontab 添加定时调用任务即可。在系统文件 /etc/crontab 添加一行内容：39 1,13 * * * root /usr/bin/bash /path/to/certbot-updater.sh上述定时计划表示，每天 01:39 和 13:39 ，以 root 身份运行 certbot 的证书更新脚本。最后，重启 cron 守护进程：$ sudo systemctl restart crond参考 Changing RHEL Port Numbers 将 Amazon Linux 2 上的 Apache Web 服务器配置为使用 SSL/TLS Certbot: Nginx On CentOS/RHEL7 Advanced Apache Configuration with SELinux on RHEL 7" }, { "title": "Shadowsocks Server 配置", "url": "/posts/ssserver-config/", "categories": "Tech, Shadowsocks", "tags": "shadowsocks", "date": "2018-06-25 14:18:00 +0800", "snippet": "配置服务端采用 JSON 文件存储配置信息，可分单用户和多用户两种情况：单用户{ &quot;server&quot;: &quot;0.0.0.0&quot;, &quot;server_port&quot;: 10000, &quot;password&quot;: &quot;mypasswd&quot;, &quot;timeout&quot;: 300, &quot;method&quot;: &quot;aes-256-cfb&quot;}多用户{ &quot;server&quot;: &quot;0.0.0.0&quot;, &quot;port_password&quot;: { &quot;1001&quot;: &quot;password_a&quot;, &quot;1002&quot;: &quot;password_b&quot; }, &quot;timeout&quot;: 300, &quot;method&quot;: &quot;aes-256-cfb&quot;}启动命令$ /bin/ssserver -c /path/to/config.json -d start参数说明：-c 表示加载指定配置文件-d 表示后台模式参考 Configure Multiple Users" }, { "title": "KC2 修改有目录的 MOBI", "url": "/posts/kc2-modify-mobi/", "categories": "Living, Kindle", "tags": "mobi, kc2", "date": "2018-05-07 20:29:00 +0800", "snippet": "缘由vol.moe 上下载的《灌篮高手》，里面很多跨页内容被分到两页。正确处理应该跨页合并成一页，替代掉原来的两页。另外，有些页扫描不准，把邻页的边缘都截进来了。这两种情况，都可通过 KC2 ( Kindle Comic Creator )把 PS 处理后的页替代原来的内容。几天后在 iPad 上看漫画，发现第一次处理时漏了一些未处理的瑕疵页。遂再补充完成，不过 KC2 编辑有目录的 EPUB 3 资源，会出现一些超链接错误，需要额外解决。本文就是解决 KC2 二次构建 EPUB 3 错误的一个案例。错误出现首先用 KindleUnpack 解压 MOBI 为 EPUB 3 格式，在 mobi8/OEBPS/Images/ 中选定瑕疵页，此张是边缘截边不准确：用 PS 处理白边后，内容居中：用 KC2 插入新图，构建 MOBI 时出现错误警告「无法解析目录中的超链接」：追踪问题根据控制台错误提示，在 mobi8/OEBPS/Text/nav.xhtml 中找到引用 part0026xhtml 的问题行：通过页码 Page-30 在 mobi8/OEBPS/toc.ncx 里找到正确的 src 路径：所以，问题症结在于：KC2 导入解压的 EPUB 3 文件内的 mobi8/OEBPS/content.opf 时，会从同级目录的 toc.ncx 及 Text/nav.xhtml 中导入目录信息。对于 已有目录的 MOBI 文件（如本例所述、此前经过 KC2 编辑的 MOBI，会自动生成页码目录），经过 KC2 更新图片资源再执行构建，会更新 toc.ncx 内容，使其与 GUI 显示一致，但却没有自动修改 nav.xhtml 中对图片引用链接。修复错误方法 1. 维持目录 注：此方法要求在 KC2 编辑完毕后实施。此法又有两种选择：1. 暴力的方式【荐】nav.xhtml 是 KindleUnpack 执行 EPUB 3 格式解压时依照 toc.ncx 生成的内容，KC2 的构建 TOC 不依赖其目录（但不可移除整个文件）。故可直接清空 &amp;lt;ol&amp;gt;...&amp;lt;/ol&amp;gt; 之间的内容，鉴于此法不需要脚本，手动执行即可快速完成，所以推荐。2. 优雅的方式把正确的相对路径内容修正到 nav.xhtml：如果一次性修改了多张图片（有时多达两位数），手动修改效率低且容易出错，所以可使用 Python 脚本处理：#!/usr/bin/env python# -*- coding: utf-8 -*-&#39;&#39;&#39;This script will export the contents of toc.ncx to Text/nav.xhtmlRequired: - Python27 - BeautifulSoup4&#39;&#39;&#39;import osfrom bs4 import BeautifulSoupcount = 0src_path = &quot;toc.ncx&quot;dest_path = &quot;Text/nav.xhtml&quot;with open(src_path) as sf, open(dest_path) as df: soup_src = BeautifulSoup(sf, &quot;html.parser&quot;) soup_dest = BeautifulSoup(df, &quot;html.parser&quot;) soup_dest.body.nav.ol.clear() for nav_point in soup_src.find_all(&#39;navpoint&#39;): page = nav_point.navlabel.text.strip() src = nav_point.content.get(&#39;src&#39;) if src.startswith(&#39;Text&#39;): src = src[len(&#39;Text/&#39;):] else: src = &quot;../&quot; + src count += 1 print(&quot;\\t{} -&amp;gt; {}&quot;.format(page, src)) tag_a = soup_dest.new_tag(&quot;a&quot;, href=src) tag_a.append(page) tag_li = soup_dest.new_tag(&quot;li&quot;, tag_a) tag_li.append(tag_a) soup_dest.body.nav.ol.append(tag_li) dump = soup_dest.prettify()os.remove(dest_path)with open(dest_path, &quot;w&quot;) as file: file.write(dump.encode(&#39;utf-8&#39;))print(&quot;Done, updated {} urls.&quot;.format(count))脚本逻辑是以 toc.ncx 内容为基准，将其内容导出到 nav.xhtml，将上述脚本放置于 toc.ncx 同级目录运行即可。方法 2. 清空目录如果 KC2 的 GUI 上编辑好的目录是没有具体意义的 Page-X，可以清空 MOBI 的目录信息。需要清除的内容有两部分： 清空 toc.ncx 文件 &amp;lt;navMap&amp;gt;...&amp;lt;/navMap&amp;gt; 之间的内容。 清空 nav.xhtml 文件 &amp;lt;ol&amp;gt;...&amp;lt;/ol&amp;gt; 之间的内容。上述二法取其一，KC2 重新构建，错误驱散，生成了新的 MOBI。最后使用 KindleStrip 去除新 MOBI 里的 AWZ 部分缩小体积，即去冗。后续优化在上文错误出现中提及到，原图是 222 KB，经过 PS 修改后，输出为 975 KB。而这样变大的图片插进 KC2，再构建后的 MOBI 体积会比原来的大一点。具体涨幅与插入的 PS 处理图片数量成正比。如本例，KC2 构建后的体积为 53.1 MB:为了缩小体积，需要做一些重复的处理： KindleUnpack 解压上步 MOBI。 KC2 构建上步产生的 content.opf。 KindleStrip 最后分割上步 MOBI。体积优化后的结果，体积缩小到 52.8 MB：OK，至此得到了一个图页正确、体积小巧的完美 MOBI 文件了，可喜可贺。其他方式曾经考虑过，直接在 mobi8/OEBPS/Images/ 中替换处理好的图片，然后通过 KC2 导入图片新建生成 MOBI，免除修改 nav.xhtml 之苦。可惜 KC2 新建的 MOBI 体积太过庞大，譬如 60 MB 的文件，KC2 新建出来的可达 100 MB。所以作罢，不考虑 KC2 新建。此外，如果可以不需要 EPUB 3 特性的话，在 KindleUpack 解压 MOBI 的时候可选择输出为 epub2 格式，这样就没有 nav.xhtml 文件的存在，也就可以省去了更正 nav.xhtml 的步骤了。总结根据此次宝贵的经历，现得出一套处理 KC2 二次（或以上）构建 EPUB 3 的流程： nav.xhtml 清除目录或用脚本修正中的图片链接。 KC2 重新构建 MOBI，然后 KindleStrip 去冗。 解压上步 MOBI，再一次 KC2 构建 → KindleStrip 去冗。" }, { "title": "罗马复兴攻略", "url": "/posts/strategy-for-aoe/", "categories": "Living, Game", "tags": "age of empires", "date": "2018-03-16 22:19:00 +0800", "snippet": "罗马复兴（帝国时代）是微软在 1999 年发行的一款经典即时战略游戏。第一次接触是在 2001 年左右。 玩了十七年，至今依然十分喜爱，多次在 安装→删除→再安装 之间往复循环。记录一下攻略，供日后有空再重玩时，快速恢复竞技水平。 注：以下战略均针对明图丘陵地形，非全科技图，民族殷商。快捷键农民 组合键 功能说明 B+E 建住房 B+G 建谷仓 B+S 建仓库 B+F 建农田 B+M 建市场 B+C 建政府中心 B+N 建主营 B+B 建步兵营 B+A 建射箭场 B+L 建马厩 B+K 建炮房 B+P 建神殿 主营 组合键 功能说明 H+C 主营出农民 兵营 组合键 功能说明 Ctrl+A 射箭场迭代 Ctrl+L 马厩迭代 Ctrl+K 炮房迭代 基础攻略石器时代总体需要的资源为 3 堆果 + 2 只象 + 3 堆森林。开局 4 农采肉，6 农伐木。往后新出的农一直增加到采肉作业。人口扩展到 20 开始，扩大伐木队伍，每新增 2 农增建第 2、3 号仓库材木，发展到 25 农民时（07:22 ~ 8:00 之间），仓库的结构一般为2 BG，3 BS。保持 10 农伐木，15 农采肉的产业结构，升工具时代。工具时代农民在 25 基础上 + 1，BA 及 BM 后升铜器时代（09:55 - 10:00 之间）。升级间隙，把产业结构调整为 10 农采肉/耕田，15 农伐木。与此同时，扩建 BA 数量至 5 个，BE 适量。BM 伐木效率升第一级。铜器时代铜器时代（13:36 - 14:10 之间）5 马不断。20:00 开始派农采黄金，BM 伐木效率升第二级。农田 28 + 块，30 农民伐木，10 农采集黄金，在 30:00 左右还没分出胜负，就开始升铁器时代。升级间隙，BS 升级装甲以及攻击，BC 确保升级士兵生命值、房屋生命值。资源上注意预留 1200 木、800 金为铁骑双头马升级。铁器时代铁器时代升完马上升双头马，两支各 25 个双头马出完，考虑升级终极黑骑射手（40:00 以后）。进阶攻略建筑 位移发展：当主营周围森林稀少难以防卫，或者离队友太远、对家太近时，可以把人员和 BS 往后移，此方法借鉴了游牧的特点。 田屋路障：农田与地图边角之间用一排屋子连接，锁死敌方绕着农田周围乱窜的骑兵。 带兵 引蛇出洞：抓住常人「两颗炮弹不会掉进同一个弹坑」的惯性认知，屠农时可以分两队兵进行。第一队先杀几个农吸引敌人防守注意力，制造「弹坑」，然后引蛇出洞，第二队兵悄然潜入农堆大屠杀。 仙女撒花：一队数量较多的骑兵勇闯敌方主营时，通常后面会紧跟着对方的守兵，此时大队在乱闯的同时，不断从队伍中分离三到五个兵的小队伍，分插到对方不同的农民汇集处，拉宽进攻面，增加对方防守难度。同时也有效避免对方用屋子堵死前进方向的概率。 开后门：遇到老手玩家，一般会使用 BE 方式堵住我兵退路。所以突击进去敌后腹地时，留一到两个兵在退路出口（通常就是突破拆屋的缺口），当遇到对方 BE 阻路，那停驻的兵会自动消除路障。 跑路混战的时候，经常会遇到被对方二打一。主营守不住就要果断撤农民，光指望队友救兵不是长久之计。跑路的时候先保证肉木供应不中断，肉方面选择果粮，木材则在敌方低概率出现的森林旁建 BN 砍伐。当果采完，可选择进友军大本营耕田。如果兵房不给拆，则保证兵不断出，然后反击。如果被拆，则在隐蔽处建至少五个 BA。反击时使用游牧法，专攻敌方软肋 —— 农民。见农就杀，见兵就跑，尽量杀遍所有敌对玩家农民，破坏经济，不留一家独大。" }, { "title": "GitHub &amp; Coding 双线部署 Jekyll 博客", "url": "/posts/dual-deployment-Jekyll-Blog-on-GithubPages-n-CodingPages/", "categories": "Tech, Website", "tags": "jekyll, github pages, coding pages, dnspod", "date": "2018-03-15 11:53:00 +0800", "snippet": "自从 Jekyll 博客放在 GitHub Pages，代码和服务托管都省了。可是国内访问速度一直要死不活的，ping 速一直在 140 ms 上下，运气好碰上流量空闲时段，偶尔会回落到 80 ms 等级，当然，只是偶尔。经过实施了优化源码、静态资源从国外 CDN 拷贝到项目本地的方法去提速，平时打开博客主页，一般肉眼测速，还是要 2s - 3s 附近，加载项延时一直卡在 GitHub 上。难道打开自己的博客都要挂 VPN 提速？这不是我想要的生活啊，于是上万能的 Internet 寻求解决方案。不出片刻，发现了一条光明大道：Coding Pages，另外还有个意外收获 DNSPod。简单介绍一下这两个平台：国内曾经有一家公司叫 GitCafe，提供代类似 GitHub 的源码托管服务，几年前给 Coding 收购了，现在 Coding Pages 对应的就是 GitHub Pages。DNSPod 则是国内的免费 DNS 解析平台。为何选择这对组合？因为 Coding 平台服务器在国内，访问速度自然是极速的。再者，增加一份项目副本，减少了数据丢失的风险。但仅仅选择迁移到国内，就等于放弃了 GitHub Pages 那边的出口。DNSPod 则解决了这个尴尬，通吃国内外线路，根据入口的 IP 智能跳转墙内外。最后最满意的一点就是，它们都 不用备案。简而言之，国内访问博客增速，从两方面下手： GitHub 上的项目搞个镜像到国内 Coding Pages。 DNSPod 对国内外线路访问的作动态域名解析。前提 拥有一个国外购买的独立域名，本人的是 GoDaddy 产品。 GitHub Pages 已经运行了一个完整的静态网站，并绑定到个人独立域名。过程国内镜像首先，拥有一个 Coding.net 注册的账号，等级必须在银级以上。在其上面创建一个 个人项目，可选为 私有 属性，名字为{username}.coding.me：username 是 Coding 账号的用户名。其次，为本地的仓库添加一个指向 Coding 的远程地址，把项目推到 master 分支。最后，配置 Coding Pages 服务。在 Coding 项目控制台，代码→Pages服务中完成。动态解析域名1.还是 Coding 项目控制台，代码→Pages服务→自定义域名绑定目标域名，如本站设定为三级域名 blog.cotes.in2.GoDaddy 控制台为个人域名设置域名服务器为 DNSPod 的免费套餐地址：f1g1ns1.dnspod.netf1g1ns2.dnspod.net3.注册获得一个 DNSPod 账号，在记录管理添加 GoDaddy 的域名，根据需要配置 CNAME 及其他 A 类地址。因为 DNSPod 可以识别国内访问外线路，所以可使用两个 CNAME 记录，分别指国内外两个博客的域名，动态指向 GitHub Pages 和 Coding Pages 项目的子域:此外还建议在域名设置→功能设置开启 搜索引擎推送 和 CNAME加速。检验成果江湖规矩，有事没事 ping 一下，国内访问 blog.cotes.in：直接解析到 Coding Pages，30 ms 级别的速度，立竿见影啊有木有。再看看国外访问：和预期一样，跳转到 GitHub Pages 的子域名了，速度飞快！后话至此，故事结束了吗？不存在的。完成上述工作后，兴冲冲地清空手机浏览器缓存刷博客。第一眼看屏幕？马上黑人问号，这是什么？？？第一反应：是不是输错 URL 了？于是再访问一次，页面马上是正常的博客首页了。再来几次，好像没问题，都是飞速进入到博客首页。但是隐约中还是感到事有蹊跷，于是再清一下缓存和历史数据，在 100% 保证 URL 正确下，再访问一次，果不其然，Coding 的 404 页面又出来了！火速追根溯源，在 Coding 项目Pages服务底部，官方一段隐晦的声明中找到了问题：OK，拿人手短，吃人嘴软，怒加之。一天后，项目控制台收到了审核通知，强制跳转页去掉了。参考资料 创建静态 Coding Pages Coding 会员体系介绍" }, { "title": "macOS 环境快捷键", "url": "/posts/shortcut-on-macos/", "categories": "Tech, Mac", "tags": "macos, chrome, sublime, intellij, idea", "date": "2018-03-07 15:46:00 +0800", "snippet": "在 macOS 中，有些组合快捷键很实用，但是容易忘记。故记下，省去日后 Google 的流量费，早餐加个蛋。为了精简描述，本文为以下按键采用缩写：⌘→command→cmd⌃→control→ctrl 缩写绝对不是偷懒不想码多几个字母。macOS 用途 快捷键 固定/隐藏 Docker alt+cmd+D 熄灭屏幕 shift+ctrl+power 截取全屏 shift+cmd+3 截取选择区域 shift+cmd+4 截取活动窗口/录像 shift+cmd+5 剪切文件 cmd+C → alt+cmd+V 光标跳到字符串头部 ctrl+A 光标跳到字符串尾部 ctrl+E 选中光标至字符串起始部分 shift+ctrl+A 选中光标至字符串末端部分 shift+ctrl+E Finder 开启/隐藏 不可见文件（macOS 10.12 以上） shift+cmd+. 显示桌面 F11 Terminal 用途 快捷键 在命令历史中跳转 cmd+&amp;uarr;/&amp;darr; 当前路径打开新 tab cmd+T 左右切换 tab shift+cmd+&amp;larr;/&amp;rarr; Chrome 用途 快捷键 恢复上次打开的所有 Tab shift+cmd+T 删除搜索智能填充的记录 &amp;uarr;/&amp;darr; 选中 → fn+shift+delete 当前 tab 切换为 HomgPage shift+cmd+H 开启/关闭 DevTools alt+cmd+I 或 F12 跳到指定 Tab cmd+num 左右切换 Tab Opt+cmd+&amp;larr;/&amp;rarr; 全屏 ctrl+cmd+F 全屏隐藏/显示 tabs shift+ctrl+F 显示/隐藏书签栏 shift+ctrl+B Sublime Text 用途 快捷键 备注 打开文件 cmd+P   选择高亮语法 shift+cmd+P   文本编辑：跳到指定行 ctrl+G   代码缩进美化 shift+ctrl+H 需要安装 HTML/CSS/JS Prettify 插件 IntelliJ IDEA 用途 快捷键 全局搜索 双击shift 定位文件 cmd+O 定位 Class shift+cmd+O 重命名项目/模块 shift+F6 运行 Class ctrl+R Debug Class ctrl+D 清除无效 import alt+ctrl+O 批量代码缩进 选中代码 → alt+ctrl+L 生成 main 函数 psvm → enter 生成 System.out.println(); sout → enter 编辑类 用途 快捷键 选取光标至行头 shift+cmd+&amp;larr; 选取光标至行末 shift+cmd+&amp;rarr; 格式化选中代码块 alt+cmd+L 编辑位置后退 alt+cmd+&amp;larr; 编辑位置前进 alt+cmd+&amp;rarr; " }, { "title": "Jekyll 代码块展示", "url": "/posts/jekyll-code-snippet/", "categories": "Tech, Website", "tags": "jekyll", "date": "2018-02-26 21:18:00 +0800", "snippet": "展示代码高亮是每个技术博客与生俱来的使命，而展示行号，也是一个不可或缺的需求。对 Jekyll 用户的好消息是，官方对此提供了友好的支持。语法高亮常规的 Markdown 语法：使用 ``` 或者 ~~~ 符号可以展示语法高亮代码块。另外，也可以使用 Jekyll 的 highlight tag，例如，展示一段 HTML 代码：{% highlight html %}&amp;lt;p&amp;gt;This is some text in a paragraph.&amp;lt;/p&amp;gt;{% endhighlight %}显示行号有两种方式可以选择：1. 使用 Kramdown 配置按这种方法可以对常规的 Markdown 的代码段自动显示行号，故为首选。启用时，在 _config.yml 中添加以下配置：kramdown: syntax_highlighter: rouge syntax_highlighter_opts: # Rouge Options › https\\://github.com/jneen/rouge#full-options css_class: highlight span: line_numbers: false block: line_numbers: true start_line: 12. 使用 highlight tag在 highlight 后面声明类 linenos 也可以显示行号:{% highlight html linenos %}&amp;lt;p&amp;gt;This is some text in a paragraph.&amp;lt;/p&amp;gt;{% endhighlight %}特殊代码处理Markdown 解析代码块时，如遇到 Liquid 的源码，由于转义字符 { 及 }，会使用得 Liquid 的部分不被渲染。举个例子，假设源代码是：```liquid&amp;lt;p&amp;gt;{% if site.data.showAuthor %}Author:{{ site.data.author }}{% endif %}&amp;lt;/p&amp;gt;```那么 Jekyll 编译后的 HTML 结果是：&amp;lt;p&amp;gt;&amp;lt;/p&amp;gt;可见 Liquid 部分（{% if %}...{% endif %}）已经丢失了。为此，Jekyll 提供了一种优雅的解决方法：用标签{% raw %} 与{% endraw %} 包围含转义字符代码段即可:{% raw %}```liquid&amp;lt;p&amp;gt;{% if site.data.showAuthor %}Author: {{ site.data.author }}{% endif %}&amp;lt;/p&amp;gt;```{% endraw %}输出：&amp;lt;p&amp;gt;Author: Bob&amp;lt;/p&amp;gt;使用场景的考虑无论是需要显示语法高亮还是行号，都推荐以配置 kramdown 选项的方式去实现，毕竟效率第一。当然了，如果你是重度编码癖坚持要敲完一大串词组 {% highlight %}...{% endhighlight %}，那么请随意享受宪法赋予你的自由。参考 Jekyll: Code snippet highlightingPermalink Markdown Options" }, { "title": "Jekyll 的 Categories 设计", "url": "/posts/jekyll-categroies-design/", "categories": "Tech, Website", "tags": "jekyll", "date": "2018-02-25 16:29:00 +0800", "snippet": "当博客开发进行到 Category 部分时，很多头疼的问题接踵而来： 类目如何分层，分多少层？ 顶级分类能不能允许文章与子分类同存？ 如何实现方便快捷的交互 UI？思考的过程中仔细参阅了 Jekyll Docs，还有 Google 上一些关于 WordPress 的分类规则文章，以及 Evernote 的产品设计，最后做出以下设计。设计目标 出于归类精简的初衷，类目最多分两级。 一级分类下，既可展示子分类，也有入口可直接展示所有文章。 博客顶栏 Categories 模块展示所有顶级分类及其各自的子类（文章列表隐藏）。交互点击分类名称进入新页面，展示所有该分类下的文章列表。一级分类则显示根目录文章以及各个子分类下的所有文章。实现细节 下文实现环境为 Bootstrap 3, 图标为 Fontawesome 系列。Front matter约定在撰写 Post 时，分类定义可用 category 或 categories 定义，但是必须严格遵守 YAML 语法.单个分类用 category 声明e.g.category: live # 正确！category: [live, food] # 错误一个以上分类用 categories 声明，其值为 YAML 数组，但是元素数量不能超过 2 个。e.g.categories: live # 允许，但是不建议categories: [live, food] # 正确categories: [live, food, drink] # 错误，分类层数超过2定义 Category 样式在目录 _layout 中新建文件 category.html，添加源码：---layout: default---&amp;lt;row&amp;gt; &amp;lt;div class=&quot;col-sm-12&quot;&amp;gt; &amp;lt;h1&amp;gt; &amp;lt;i class=&quot;far fa-folder-open&quot;&amp;gt;&amp;lt;/i&amp;gt;&amp;amp;nbsp;{{ page.title }}&amp;amp;nbsp;&amp;amp;nbsp; &amp;lt;span class=&quot;badge&quot;&amp;gt;{{ site.categories[page.category] | size }}&amp;lt;/span&amp;gt; &amp;lt;/h1&amp;gt; &amp;lt;ul&amp;gt; {% for post in site.categories[page.category] %} &amp;lt;li&amp;gt; &amp;lt;h5&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;{{ post.date | date_to_string }}&amp;amp;nbsp;&amp;amp;nbsp;&amp;lt;/span&amp;gt; &amp;lt;a href=&quot;{{ post.url | absolute_url }}&quot;&amp;gt;{{ post.title }}&amp;lt;/a&amp;gt; &amp;lt;/h5&amp;gt; &amp;lt;/li&amp;gt; {% endfor %} &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt;&amp;lt;/row&amp;gt;生成每个 Category 页为了实现每个页面展示某个分类下的 Post 列表，需要为每个分类实现一个独立的静态页面。在 Jekyll 工程根目录创建一个文件夹 category，然后在其内以每个分类的名字命名，依次创建新的 HTML 文件。例如对于分类 live，则页面命名为 live.html，内容为：---layout: categorytitle: Livecategory: live---在建站初期，文章数量较少时这种手动方式还是可以实施的。但是，当文章数量暴涨的时候，这种冗余的操作就显得很费时费力了，所以可以用 Python 脚本完成这项工作。自动化脚本页面创建的 Python 实现：import osimport globimport yamlimport shutilPOSTS_PATH = &#39;_posts&#39;CATEGORIES_PATH = &#39;category&#39;CATEGORY_LAYOUT = &#39;category&#39;def get_front_matter(path): end = False front_matter = &quot;&quot; with open(path, &#39;r&#39;) as f: for line in f.readlines(): if line.strip() == &#39;---&#39;: if end: break else: end = True continue front_matter += line return front_matterdef get_categories(): all_categories = [] for file in glob.glob(os.path.join(POSTS_PATH, &#39;*.md&#39;)): meta = yaml.load(get_front_matter(file)) try: category = meta[&#39;category&#39;] except KeyError: try: categories = meta[&#39;categories&#39;] except KeyError: err_msg = ( &quot;[Error] File:{} at least &quot; &quot;have one category.&quot;).format(file) print(err_msg) else: if type(categories) == str: error_msg = ( &quot;[Error] File {} &#39;categories&#39; type&quot; &quot; can not be STR!&quot;).format(file) raise Exception(error_msg) for ctg in meta[&#39;categories&#39;]: if ctg not in all_categories: all_categories.append(ctg) else: if type(category) == list: err_msg = ( &quot;[Error] File {} &#39;category&#39; type&quot; &quot; can not be LIST!&quot;).format(file) raise Exception(err_msg) if category not in all_categories: all_categories.append(category) return all_categoriesdef generate_category_pages(): categories = get_categories() if os.path.exists(CATEGORIES_PATH): shutil.rmtree(CATEGORIES_PATH) os.makedirs(CATEGORIES_PATH) for category in categories: new_page = CATEGORIES_PATH + &#39;/&#39; + category + &#39;.html&#39; with open(new_page, &#39;w+&#39;) as html: html.write(&quot;---\\n&quot;) html.write(&quot;layout: {}\\n&quot;.format(CATEGORY_LAYOUT)) html.write(&quot;title: {}\\n&quot;.format(category.title())) html.write(&quot;category: {}\\n&quot;.format(category)) html.write(&quot;---&quot;) print(&quot;[INFO] Created page: &quot; + new_page) print(&quot;[INFO] Succeed! {} category-pages created.\\n&quot; .format(len(categories)))def main(): generate_category_pages()main()Python 脚本的作用是搜集 _posts 目录下的所有文章的 category 或 categories，分别为每个获取的分类名建立一个同名的.md定义文件，存放于 category 目录下，该目录为自动创建，每次运行脚本都会覆盖一遍。页面采用的样式是上一步定义的 _layout/category.html。每次新添/删除 Post，或者修改已有 Post 的 Categories 信息时，都应该运行一次上述脚本。分类动态展开的实现在 Categories 总览页面，实现折叠的效果:二级分类页面展示实现逻辑：{% assign sort_categories = site.categories | sort %}{% for category in sort_categories %} {% assign category_name = category | first %} {% assign posts_of_category = category | last %} {% assign first_post = posts_of_category[0] %} {% if category_name == first_post.categories[0] %} {% assign sub_categories = &quot;&quot; %} {% for post in posts_of_category %} {% if post.categories.size &amp;gt; 1 %} {% assign sub_categories = sub_categories | append: post.categories[1] | append: &quot;|&quot; %} {% endif %} {% endfor %} {% assign sub_categories = sub_categories | split: &quot;|&quot; | uniq %} {% assign sub_categories_size = sub_categories | size %}&amp;lt;div class=&quot;panel-group&quot;&amp;gt; &amp;lt;div class=&quot;panel panel-default&quot;&amp;gt; &amp;lt;div class=&quot;panel-heading&quot; id=&quot;{{ category_name }}&quot;&amp;gt; &amp;lt;i class=&quot;far fa-folder&quot;&amp;gt;&amp;lt;/i&amp;gt;&amp;amp;nbsp; &amp;lt;a class=&quot;panel-title&quot; href=&quot;/category/{{ category_name }}.html&quot;&amp;gt;{{ category_name }}&amp;lt;/a&amp;gt;&amp;amp;nbsp; {% assign top_posts_size = site.categories[category_name] | size %} &amp;lt;span class=&quot;text-muted small&quot;&amp;gt; {{ sub_categories_size }} folder{% if sub_categories_size &amp;gt; 1 %}s{% endif %}, {{ top_posts_size }} post{% if top_posts_size &amp;gt; 1 %}s{% endif %} &amp;lt;/span&amp;gt; &amp;lt;a data-toggle=&quot;collapse&quot; href=&quot;#grp_{{ category_name }}&quot; class=&quot; {% if sub_categories_size &amp;lt;= 0%}inactiveLink{% endif %}&quot;&amp;gt; &amp;lt;i class=&quot;fas fa-angle-down&quot; style=&quot;float: right; padding-top: 0.5rem;&quot;&amp;gt;&amp;lt;/i&amp;gt; &amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; {% if sub_categories_size &amp;gt; 0 %} &amp;lt;div id=&quot;grp_{{ category_name }}&quot; class=&quot;panel-collapse collapse&quot;&amp;gt; &amp;lt;ul class=&quot;list-group&quot;&amp;gt; {% for sub_category in sub_categories %} &amp;lt;li class=&quot;list-group-item&quot; style=&quot;padding-left: 4rem;&quot;&amp;gt; &amp;lt;i class=&quot;far fa-folder&quot;&amp;gt;&amp;lt;/i&amp;gt;&amp;amp;nbsp;&amp;lt;a href=&quot;/category/{{ sub_category }}.html&quot;&amp;gt;{{ sub_category }}&amp;lt;/a&amp;gt; {% assign posts_size = site.categories[sub_category] | size %} &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;&amp;amp;nbsp;{{ posts_size }}&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; {% endfor %} &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt; {% endif %} &amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt; {% endif %}{% endfor %}考虑锦上添花，在顶类开合状态切换的同时，更改文件夹符号以及尖头符号的方向，jQuery 的实现：$(function() { var prefix = &quot;grp_&quot;; $(&quot;.collapse&quot;).on(&quot;hide.bs.collapse&quot;, function() { var id = $(this).attr(&#39;id&#39;).substring(prefix.length); if (id) { //兼容bootstrap首页顶栏手机尺寸缩放 $(&quot;#&quot; + id + &quot; i.far.fa-folder-open&quot;).attr(&quot;class&quot;, &quot;far fa-folder&quot;); $(&quot;#&quot; + id + &quot; i.fas.fa-angle-up&quot;).attr(&quot;class&quot;, &quot;fas fa-angle-down&quot;); } }); $(&quot;.collapse&quot;).on(&quot;show.bs.collapse&quot;, function() { var id = $(this).attr(&#39;id&#39;).substring(prefix.length); if (id) { //兼容bootstrap首页顶栏手机尺寸缩放 $(&quot;#&quot; + id + &quot; i.far.fa-folder&quot;).attr(&quot;class&quot;, &quot;far fa-folder-open&quot;); $(&quot;#&quot; + id + &quot; i.fas.fa-angle-down&quot;).attr(&quot;class&quot;, &quot;fas fa-angle-up&quot;); } });});至此，所有工作完成，具体效果可跳到 Categories 板块体验。" }, { "title": "建站简史", "url": "/posts/story-of-this-site/", "categories": "Tech, Website", "tags": "story", "date": "2018-02-24 22:19:00 +0800", "snippet": "自 2016 年起，国内博客平台的相继要求绑定手机或收费，且时不时出现泄漏、售卖用户信息的恶性事件。为了减少日后接到诈骗骚扰电话的次数，我决心逃离这个丑态百出的圈子。往后的时间，对技术或生活中很多问题的解决方案，都是草草记录在 Evernote 上。毕竟 Evernote 是个专注笔记的平台，无法实现博客的那种自由度，因此搭建私人博客的需求显得尤为迫切。回顾过去，多年前曾试玩过极其流行的 WordPress。体验一番后，感觉它过于复杂臃肿、吃硬件，在一台美区的 VPS 上跑过几个月，一篇文章都没写，最后随着 VPS 到期而销声匿迹了。到了 2017 年岁末，无意中发现了 Jekyll 加 GitHub Pages 这个新方式：Jekyll 是成熟的静态网站生成器，构建的静态网站轻量小巧不吃硬件，而 GitHub Pages 则是个免费托管网站的 Web Server。采用最经济和稳定的方式去存储、分享自己的技术和生活心得，何乐而不为呢？于是马上调研这个构想的可行性。Jekyll 官方有不少现成的主题，GitHub 上也有很多开发者提供了自己的设计方案（Lagrange 是本站最初使用的主题），可惜总体来说都没有十分符合个人口味和使用需求。那不如写个全新的博客吧？当我瞄了一眼自己的前端技能包，发现空空如也。不过，学习是人一生的使命，于是白手起家：HTML、CSS、JavaScript、jQuery、Bootstrap、Liquid 等，此前未曾涉猎的领域，在建站的过程中，一个个翻了一遍。截至本站首次上线（2018/02/24），对于开发 Jekyll 网站，已基本可以胜任了。后续版本还会继续为本站添加实用的功能及美化样式。" }, { "title": "为漫画 MOBI 添加目录", "url": "/posts/override-kindle-comic-mobi/", "categories": "Living, Kindle", "tags": "mobi, kc2", "date": "2017-10-17 22:33:05 +0800", "snippet": "总体思路 使用 KindleUnpack1把 mobi 文件解压分割。 使用 Kindle Comic Creator2(下简称KC2)打开 mobi8/OEBPS/content.opf 重制（可加目录），保存为 KF8 的 mobi 文件。因为 KC2 的输出为双模的 mobi，即里面既有 mobi 也有 azw3，所以体积为源文件的2倍或更多，故需再分解。 使用 KindleStrip3 把 2 步骤的输出文件去除冗余即可获得目标 mobi。具体执行实例 Kindle Comic Creator 制作目录部分略麻烦，再次需要具体阐述。 PS：以下实例运行平台为 Windows 10。1.KindleUnpack 解压打开 KindleUnpack 工具解压，源文件: 七龙珠完全版26-30本.mobi，体积 215 MB。解压目录为 C:\\Users\\Cotes\\Desktop\\WorkPath\\unpack-out：2.KindleComicCreator 编辑打开 KC2，通过打开一本书 → 选取输出目录下的 mobi8\\OEBPS\\content.opf，在 GUI 中修改每节的关键页面 label，删除多余页，以及改变内容排序。原始页面排序:调整后的页面排序: 小技巧：KC2 可以在查看 → 工具栏 → 漫画工具栏中，调整 设计 预览的大小，方便完整阅读图片。编辑完毕，点击图书设置 → 修改元数据，完毕后，执行构建 → 构建并预览生产编译结果。3.修改 toc.ncx 结构使用文本编辑器打开 mobi8/OEBPS/toc.ncx，去除 &amp;lt;navMap&amp;gt; 自动生产多余的目录节点 &amp;lt;navPoint&amp;gt;，格式为 Page-{X}，需要的话还可以改变章节的层级结构，如本例，初始是单层结构：...&amp;lt;navMap&amp;gt; &amp;lt;navPoint playOrder=&quot;1&quot; id=&quot;toc-1&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;Vol_26&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0001.xhtml&quot; /&amp;gt; &amp;lt;/navPoint&amp;gt; &amp;lt;navPoint playOrder=&quot;2&quot; id=&quot;toc-2&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;Page-1&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0000.xhtml&quot; /&amp;gt; &amp;lt;/navPoint&amp;gt; &amp;lt;navPoint playOrder=&quot;3&quot; id=&quot;toc-3&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;Page-7&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0006.xhtml&quot; /&amp;gt; &amp;lt;/navPoint&amp;gt; &amp;lt;navPoint playOrder=&quot;4&quot; id=&quot;toc-4&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;No.375 比达、杜拉格斯出发&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0007.xhtml&quot; /&amp;gt; &amp;lt;/navPoint&amp;gt; &amp;lt;navPoint playOrder=&quot;5&quot; id=&quot;toc-5&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;Page-9&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0008.xhtml&quot; /&amp;gt; &amp;lt;/navPoint&amp;gt; ...&amp;lt;/navMap&amp;gt;...对应默认效果是：精简及改变为二级结构后：...&amp;lt;navMap&amp;gt; &amp;lt;navPoint playOrder=&quot;1&quot; id=&quot;toc-1&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;Vol_26&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0001.xhtml&quot; /&amp;gt; &amp;lt;navPoint playOrder=&quot;4&quot; id=&quot;toc-4&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;No.375 比达、杜拉格斯出发&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0007.xhtml&quot; /&amp;gt; &amp;lt;/navPoint&amp;gt; &amp;lt;navPoint playOrder=&quot;19&quot; id=&quot;toc-19&quot;&amp;gt; &amp;lt;navLabel&amp;gt; &amp;lt;text&amp;gt;No.376 比达充满自信&amp;lt;/text&amp;gt; &amp;lt;/navLabel&amp;gt; &amp;lt;content src=&quot;Text/part0236.xhtml&quot; /&amp;gt; &amp;lt;/navPoint&amp;gt; &amp;lt;/navPoint&amp;gt; ...&amp;lt;/navMap&amp;gt;...修改后的视图效果:4.KindlePreviewer 编译把 mobi8/OEBPS/content.opf 拖进 KindlePreviewer 空白处，即可触发编译:5.KindleStrip 去冗余此时在上步生成的 mobi8/OEBPS/converted-content-opf 目录内，生成了一个 444 MB 的 mobi,拷贝一个 KindleStrip 的 python 脚本进此目录：按住shift+右击，在此目录运行 cmd，执行 python 脚本，语法为：kindleStrip.py INPUT OUTPUTINPUT 替换为输入路径OUTPUT 替换为输出路径e.g., 本例 OUTPUT 为「七龙珠完全版26-30本[修].mobi」，执行如下：最后可得到体积缩小一半的最终成品 mobi。注意事项 KindleUnpack 必须使用 python 2.7.X，否则不能正常工作！ Calibre 转换过的 mobi 漫画都会出现白边，请不要使用其编辑漫画。扩展话题如何快速修改重置过的 mobi 文件目录？直接修改 mobi8\\OEBPS\\Text\\nav.xhtml 文件，然后 mobi8\\OEBPS\\content.opf 拷贝到 KindelPreveviewer 编译即可。相关资源 KindleUnpack &amp;#8617; Kindle Comic Creator &amp;amp; Kindle Previewer &amp;#8617; KindleStrip &amp;#8617; " } ]
